# kbo_teamstat_streamlit.py
from io import StringIO
import streamlit as st
import pandas as pd
import numpy as np
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup
import re
from datetime import datetime
import gspread
from gspread.exceptions import APIError as GspreadAPIError
from google.oauth2.service_account import Credentials
import plotly.express as px
import plotly.graph_objects as go
from zoneinfo import ZoneInfo

# -----------------------------
# í˜ì´ì§€/ìŠ¤íƒ€ì¼
# -----------------------------
st.set_page_config(
    page_title="KBO íŒ€ í†µê³„ ë¶„ì„ê¸°",
    page_icon="âš¾",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.markdown("""
<style>
    .main-header { font-size: 2.5rem; color: #1f77b4; text-align: center; margin-bottom: 2rem; }
    .metric-card { background-color: #f0f2f6; padding: 1rem; border-radius: .5rem; border-left: 4px solid #1f77b4; }
    .team-stats { background-color: #fff; padding: 1rem; border-radius: .5rem; box-shadow: 0 2px 4px rgba(0,0,0,.1); }
</style>
""", unsafe_allow_html=True)

# -----------------------------
# ìƒìˆ˜/ìœ í‹¸
# -----------------------------
TEAM_NAMES = ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']
HEADERS = {
    'User-Agent': (
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
        'AppleWebKit/537.36 (KHTML, like Gecko) '
        'Chrome/126.0.0.0 Safari/537.36'
    ),
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.6,en;q=0.4',
    'Cache-Control': 'no-cache',
    'Pragma': 'no-cache',
    'Referer': 'https://www.koreabaseball.com/Record/Team/Default.aspx',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

# KBO ì›ë³¸ URL ìƒìˆ˜
KBO_URLS = {
    'hitter_basic1': 'https://www.koreabaseball.com/Record/Team/Hitter/Basic1.aspx',
    'hitter_basic2': 'https://www.koreabaseball.com/Record/Team/Hitter/Basic2.aspx',
    'pitcher_basic1': 'https://www.koreabaseball.com/Record/Team/Pitcher/Basic1.aspx',
    'pitcher_basic2': 'https://www.koreabaseball.com/Record/Team/Pitcher/Basic2.aspx',
    'standings': 'https://www.koreabaseball.com/Record/TeamRank/TeamRankDaily.aspx',
}

def _parse_kbo_date_info_to_date(date_info: str) -> str | None:
    """'(YYYYë…„ Mì›” Dì¼ ê¸°ì¤€)' ë¬¸ìì—´ì—ì„œ YYYY-MM-DD í˜•ì‹ì˜ ê¸°ì¤€ì¼ìë¥¼ ì¶”ì¶œ."""
    try:
        if not date_info:
            return None
        m = re.search(r"(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼", str(date_info))
        if not m:
            return None
        y, mo, d = int(m.group(1)), int(m.group(2)), int(m.group(3))
        return f"{y:04d}-{mo:02d}-{d:02d}"
    except Exception:
        return None

# íŒ€ë³„ ê³ ì • ìƒ‰ìƒ(ìš”ì²­ ìš°ì„  ì ìš©). ì§€ì •ë˜ì§€ ì•Šì€ íŒ€ì€ ê¸°ë³¸ íŒ”ë ˆíŠ¸ ì‚¬ìš©
TEAM_COLOR_MAP = {
    'LG': '#B31942',      # ë°ê¸° + ì±„ë„ ë³´ì •
    'í•œí™”': '#FF8C00',     # Dark Orange
    'í‚¤ì›€': '#A45A6B',     # ì™€ì¸ìƒ‰
    'ë‘ì‚°': '#003366',     # Deep Blue
    'ì‚¼ì„±': '#1E90FF',     # ìœ ì§€
    'SSG': '#FFD700',     # ìœ ì§€
    'KT': '#4B4B4B',      # ì§™ì€ ê·¸ë ˆì´
    'ë¡¯ë°': '#FF4C4C',     # ë°ì€ ë ˆë“œ
    'KIA': '#8B0000',      # Dark Red
    'NC': '#B8860B',       # ë¸Œë¡ ì¦ˆ
}


def _build_session() -> requests.Session:
    session = requests.Session()
    retry = Retry(
        total=5,
        connect=3,
        read=3,
        backoff_factor=0.5,
        status_forcelist=(403, 429, 500, 502, 503, 504),
        allowed_methods=('GET', 'HEAD'),
        raise_on_status=False,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.headers.update(HEADERS)
    session.mount('https://', adapter)
    session.mount('http://', adapter)
    return session

SESSION = _build_session()

def _diagnose_gsheet_setup() -> str:
    msgs = []
    try:
        if "gcp_service_account" not in st.secrets:
            msgs.append("- secretsì— [gcp_service_account] ì„¹ì…˜ì´ ì—†ìŒ (.streamlit/secrets.toml í™•ì¸)")
            return "\n".join(msgs)

        gcp = dict(st.secrets["gcp_service_account"])
        required = ["type","project_id","private_key_id","private_key","client_email","client_id","token_uri"]
        missing = [k for k in required if k not in gcp or not gcp[k]]
        if missing:
            msgs.append(f"- ëˆ„ë½ëœ í‚¤: {', '.join(missing)}")

        pk = str(gcp.get("private_key", ""))
        if not pk.startswith("-----BEGIN PRIVATE KEY-----"):
            msgs.append("- private_key í˜•ì‹ ì˜¤ë¥˜: PEM í—¤ë”ê°€ ì—†ìŒ")
        if "\\n" not in gcp.get("private_key", "") and "\n" not in pk:
            msgs.append("- private_key ì¤„ë°”ê¿ˆ ëˆ„ë½ ê°€ëŠ¥ì„±: TOMLì—” \\në¡œ ì €ì¥ í•„ìš”")
        email = str(gcp.get("client_email",""))
        if not email.endswith("iam.gserviceaccount.com"):
            msgs.append("- client_email ê°’ì´ ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹˜")
        if not msgs:
            msgs.append("- secrets í˜•ì‹ì€ ì •ìƒ. Sheets/Drive API í™œì„±í™” ë° ëŒ€ìƒ ì‹œíŠ¸ ê³µìœ  ê¶Œí•œ í™•ì¸")
    except Exception as e:
        msgs.append(f"- ì§„ë‹¨ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    return "\n".join(msgs)

def _format_gspread_error(err: Exception) -> str:
    try:
        if isinstance(err, GspreadAPIError):
            status_code, reason, message = None, None, None
            resp = getattr(err, "response", None)
            if resp is not None:
                status_code = getattr(resp, "status_code", None)
                try:
                    data = resp.json()
                    err_obj = data.get("error", {}) if isinstance(data, dict) else {}
                    message = err_obj.get("message")
                    details = err_obj.get("errors") or []
                    if isinstance(details, list) and details:
                        reason = details[0].get("reason")
                except Exception:
                    message = getattr(resp, "text", None)
            parts = []
            if status_code is not None: parts.append(f"status={status_code}")
            if reason: parts.append(f"reason={reason}")
            if message: parts.append(f"message={message}")
            return "; ".join(parts) if parts else str(err)
        return str(err)
    except Exception:
        return str(err)

def get_gsheet_client():
    try:
        scope = ["https://www.googleapis.com/auth/spreadsheets","https://www.googleapis.com/auth/drive"]
        if "gcp_service_account" not in st.secrets:
            st.error("Streamlit secretsì— 'gcp_service_account' ì—†ìŒ")
            return None

        gcp = dict(st.secrets["gcp_service_account"])
        required = ["type","project_id","private_key_id","private_key","client_email","client_id","token_uri"]
        missing = [k for k in required if k not in gcp or not gcp[k]]
        if missing:
            st.error(f"gcp_service_account ëˆ„ë½ í‚¤: {', '.join(missing)}")
            return None

        pk = gcp.get("private_key","")
        if isinstance(pk, str):
            pk = pk.replace("\\r\\n","\n").replace("\\n","\n").replace("\\r","\n")
        if not str(pk).startswith("-----BEGIN PRIVATE KEY-----"):
            st.error("gcp_service_account.private_key í˜•ì‹ ì˜¤ë¥˜(PEM í—¤ë” ëˆ„ë½)")
            return None
        gcp["private_key"] = pk

        try:
            creds = Credentials.from_service_account_info(gcp, scopes=scope)
        except Exception as e:
            st.error(f"ì„œë¹„ìŠ¤ ê³„ì • ìê²© ì¦ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return None

        try:
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"gspread ì¸ì¦ ì‹¤íŒ¨: {e}")
            return None
    except Exception as e:
        st.error(f"Google Sheets ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def _extract_sheet_id_from_url(url: str) -> str | None:
    try:
        m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", str(url))
        return m.group(1) if m else None
    except Exception:
        return None

def append_simulation_to_sheet(df_result: pd.DataFrame, sheet_name="SimulationLog", base_date: str | None = None):
    try:
        client = get_gsheet_client()
        if client is None:
            st.error("êµ¬ê¸€ ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì›ì¸ ì§„ë‹¨:\n" + _diagnose_gsheet_setup())
            return

        cfg = {}
        try:
            cfg = st.secrets.get("gsheet", {}) or {}
        except Exception:
            pass

        spreadsheet_id = cfg.get("spreadsheet_id")
        spreadsheet_url = cfg.get("spreadsheet_url")
        if not spreadsheet_id and spreadsheet_url:
            spreadsheet_id = _extract_sheet_id_from_url(spreadsheet_url)

        if spreadsheet_id:
            try:
                sh = client.open_by_key(spreadsheet_id)
            except Exception as e:
                st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸(ID) ì—´ê¸° ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                return
        else:
            try:
                sh = client.open("KBO_Simulation_Log")
            except Exception:
                try:
                    sh = client.create("KBO_Simulation_Log")
                except Exception as e:
                    txt = str(e)
                    if "quota" in txt.lower() and "storage" in txt.lower():
                        st.error(
                            "Google Drive ì €ì¥ ìš©ëŸ‰ ì´ˆê³¼ë¡œ ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                            "- ë“œë¼ì´ë¸Œ ìš©ëŸ‰ í™•ë³´(íœ´ì§€í†µ ë¹„ìš°ê¸° í¬í•¨) í›„ ì¬ì‹œë„\n"
                            "- ë˜ëŠ” ê¸°ì¡´ ì‹œíŠ¸ IDë¥¼ secrets.gsheet.spreadsheet_idì— ì„¤ì • + ì„œë¹„ìŠ¤ ê³„ì •ì— í¸ì§‘ì ê³µìœ "
                        )
                    else:
                        st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                    return

        created_new_ws = False
        try:
            ws = sh.worksheet(sheet_name)
        except Exception:
            try:
                ws = sh.add_worksheet(title=sheet_name, rows="10000", cols="50")
                created_new_ws = True
            except Exception as e:
                st.error("ì›Œí¬ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                return

        now_kst = datetime.now(ZoneInfo("Asia/Seoul"))
        formatted_time = now_kst.strftime("%Y-%m-%d %H:%M:%S")
        df_out = df_result.copy()
        # ê¸°ì¤€ì¼(base_date)ì€ KBO í˜ì´ì§€ ê¸°ì¤€ì¼ì(ì˜ˆ: 2025-08-10). ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
        base_date_str = base_date if base_date else now_kst.strftime("%Y-%m-%d")
        df_out.insert(0, "base_date", base_date_str)
        df_out.insert(1, "timestamp", formatted_time)

        if created_new_ws:
            try:
                ws.append_row(df_out.columns.tolist(), value_input_option="USER_ENTERED")
            except Exception as e:
                st.warning("í—¤ë” ì¶”ê°€ ì‹¤íŒ¨(ê³„ì† ì§„í–‰):\n" + _format_gspread_error(e))

        try:
            ws.append_rows(df_out.values.tolist(), value_input_option="USER_ENTERED")
        except Exception as e:
            st.error("ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨:\n" + _format_gspread_error(e))
            return

        # st.success(f"ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ '{sheet_name}' ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error("Google Sheets ì €ì¥ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜:\n" + _format_gspread_error(e))

def _open_log_worksheet(sheet_name: str = "SimulationLog"):
    """append ì‹œ ì‚¬ìš©í•œ ë™ì¼í•œ ê·œì¹™ìœ¼ë¡œ ë¡œê·¸ ì›Œí¬ì‹œíŠ¸ë¥¼ ì—°ë‹¤.
    ìš°ì„ ìˆœìœ„: secrets.gsheet.spreadsheet_id â†’ secrets.gsheet.spreadsheet_url â†’ ì´ë¦„("KBO_Simulation_Log").
    ìƒì„±ì€ í•˜ì§€ ì•Šê³ , ì—†ìœ¼ë©´ None ë°˜í™˜.
    """
    try:
        client = get_gsheet_client()
        if client is None:
            st.info("Google Sheets ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.warning("ì§„ë‹¨ ì •ë³´:\n" + _diagnose_gsheet_setup())
            return None
        cfg = {}
        try:
            cfg = st.secrets.get("gsheet", {}) or {}
        except Exception:
            pass
        spreadsheet_id = cfg.get("spreadsheet_id")
        spreadsheet_url = cfg.get("spreadsheet_url")
        if not spreadsheet_id and spreadsheet_url:
            spreadsheet_id = _extract_sheet_id_from_url(spreadsheet_url)
        if spreadsheet_id:
            try:
                sh = client.open_by_key(spreadsheet_id)
            except Exception as e:
                st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸(ID) ì—´ê¸° ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                return None
        else:
            try:
                sh = client.open("KBO_Simulation_Log")
            except Exception:
                # ìƒì„±ì€ í•˜ì§€ ì•ŠìŒ(ì½ê¸° íƒ­)
                st.info("ë¡œê·¸ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìš°ìŠ¹ í™•ë¥  íƒ­ì—ì„œ ì‹œë®¬ì„ ì‹¤í–‰í•´ ì €ì¥í•˜ì„¸ìš”.")
                return None
        try:
            return sh.worksheet(sheet_name)
        except Exception:
            st.info(f"'{sheet_name}' ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            return None
    except Exception as e:
        st.error("ë¡œê·¸ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜:\n" + _format_gspread_error(e))
        return None

def safe_dataframe_display(df: pd.DataFrame, use_container_width=True, hide_index=True):
    try:
        df_display = df.copy()
        for c in df_display.columns:
            try:
                df_display[c] = df_display[c].astype(str)
            except Exception:
                pass
        st.dataframe(df_display, use_container_width=use_container_width, hide_index=hide_index)
    except Exception as e:
        st.error(f"ë°ì´í„°í”„ë ˆì„ í‘œì‹œ ì˜¤ë¥˜: {e}")
        st.write("ì›ë³¸ í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤:")
        st.write(df)

def normalize_team_names(df: pd.DataFrame, col: str = "íŒ€ëª…") -> pd.DataFrame:
    """íŒ€ëª… ì»¬ëŸ¼ ê³µë°±/ë¹„ê°€ì‹œë¬¸ì ì œê±° ë° í‘œì¤€í™”."""
    if df is not None and not df.empty and col in df.columns:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(r"\s+", "", regex=True)
            .str.strip()
        )
    return df

def clean_dataframe_for_display(df: pd.DataFrame) -> pd.DataFrame:
    """í‘œì‹œìš© ì •ë¦¬: IP ë¬¸ìì—´ ìœ ì§€, ìˆ˜ì¹˜ ì»¬ëŸ¼ ë°˜ì˜¬ë¦¼ í›„ ë¬¸ìì—´í™”(Arrow í˜¸í™˜)."""
    try:
        dfc = df.copy()
        if "IP" in dfc.columns:
            dfc["IP"] = dfc["IP"].astype(str)

        for c in dfc.columns:
            if c in ("íŒ€ëª…", "ìˆœìœ„", "ìµœê·¼10ê²½ê¸°"):
                continue
            if pd.api.types.is_float_dtype(dfc[c]):
                dfc[c] = dfc[c].round(3).astype(str)
            elif pd.api.types.is_integer_dtype(dfc[c]):
                dfc[c] = dfc[c].astype(str)

        return dfc
    except Exception as e:
        st.error(f"í‘œì‹œ ì •ë¦¬ ì˜¤ë¥˜: {e}")
        return df

def _parse_ip_to_decimal(ip_str: str) -> float | None:
    """'123 2/3' ë˜ëŠ” '123.1' ê°™ì€ ì´ë‹ ë¬¸ìì—´ì„ ì†Œìˆ˜ë¡œ ë³€í™˜(íˆ¬ìˆ˜ IPëŠ” ë³´í†µ 1/3 ë‹¨ìœ„)."""
    if ip_str is None:
        return None
    s = str(ip_str).strip()
    if not s:
        return None
    m = re.match(r"^(\d+)\s+(\d)\/3$", s)
    if m:
        whole = float(m.group(1)); frac = int(m.group(2))/3.0
        return round(whole + frac, 4)
    m2 = re.match(r"^(\d+)\.(\d)$", s)
    if m2:
        whole = float(m2.group(1)); tenths = int(m2.group(2))
        if tenths in (1,2):
            frac = tenths/3.0
            return round(whole + frac, 4)
        return float(s)
    try:
        return float(s)
    except Exception:
        return None

def _first_table_html(url: str) -> tuple[pd.DataFrame | None, BeautifulSoup | None]:
    """í•´ë‹¹ í˜ì´ì§€ì—ì„œ ì²« í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ ì½ê³ , soupë„ ë°˜í™˜."""
    try:
        r = SESSION.get(url, timeout=15)
        r.raise_for_status()
        try:
            if not r.encoding or r.encoding.lower() in ("iso-8859-1", "ascii"):
                r.encoding = r.apparent_encoding or 'utf-8'
        except Exception:
            r.encoding = 'utf-8'
        soup = BeautifulSoup(r.text, "html.parser")
        # read_html: ì—¬ëŸ¬ í…Œì´ë¸” ì¤‘ ì ì ˆí•œ í…Œì´ë¸” ì„ íƒ
        try:
            tables = pd.read_html(StringIO(r.text))
            if tables:
                # 'íŒ€' ë¬¸ìì—´ì´ í¬í•¨ëœ í—¤ë”ë¥¼ ìš°ì„  ì„ íƒ
                for t in tables:
                    cols_join = "".join(map(str, list(t.columns)))
                    if 'íŒ€' in cols_join or 'íŒ€ëª…' in cols_join:
                        return t, soup
                return tables[0], soup
        except Exception:
            pass
        table = soup.find("table")
        if not table:
            try:
                table = soup.select_one("table, table.tData, table.table, .record > table")
            except Exception:
                table = None
        if not table:
            return None, soup
        rows = []
        for tr in table.find_all("tr"):
            cells = tr.find_all(["th", "td"])
            if not cells:
                continue
            rows.append([c.get_text(strip=True) for c in cells])
        if not rows:
            return None, soup
        df = pd.DataFrame(rows[1:], columns=rows[0])
        return df, soup
    except Exception:
        return None, None

def _candidate_team_tokens() -> list[str]:
    return [
        'LG','í•œí™”','ë¡¯ë°','ì‚¼ì„±','SSG','NC','KIA','ë‘ì‚°','KT','í‚¤ì›€',
        'ê¸°ì•„','ëœë”ìŠ¤','íŠ¸ìœˆìŠ¤','ì´ê¸€ìŠ¤','ìì´ì–¸ì¸ ','ë¼ì´ì˜¨ì¦ˆ','ë² ì–´ìŠ¤','ë‹¤ì´ë…¸ìŠ¤','ìœ„ì¦ˆ','íˆì–´ë¡œì¦ˆ','íƒ€ì´ê±°ì¦ˆ'
    ]

def _score_table_for_teams(df: pd.DataFrame) -> tuple[int, int]:
    """í…Œì´ë¸” ë‚´ íŒ€ í† í° ë°œê²¬ ê°œìˆ˜(ìµœëŒ€ì—´, ì´í•©)ì„ ì ìˆ˜ë¡œ ë°˜í™˜."""
    try:
        tokens = _candidate_team_tokens()
        max_col_hits = 0
        total_hits = 0
        for col in df.columns:
            s = df[col].astype(str)
            hits = 0
            for tok in tokens:
                try:
                    hits += int(s.str.contains(tok, na=False).sum())
                except Exception:
                    continue
            total_hits += hits
            if hits > max_col_hits:
                max_col_hits = hits
        return max_col_hits, total_hits
    except Exception:
        return (0, 0)

def _choose_best_table_from_html(html_text: str, soup: BeautifulSoup) -> pd.DataFrame | None:
    # 1) pandasë¡œ íŒŒì‹± ê°€ëŠ¥í•œ ëª¨ë“  í…Œì´ë¸” ì ìˆ˜í™”
    best: tuple[int,int,int,pd.DataFrame] | None = None
    try:
        tables = pd.read_html(StringIO(html_text))
        for idx, t in enumerate(tables):
            max_col_hits, total_hits = _score_table_for_teams(t)
            if best is None or (max_col_hits, total_hits) > (best[0], best[1]):
                best = (max_col_hits, total_hits, idx, t)
        if best and (best[0] >= 5 or best[1] >= 10):
            return best[3]
    except Exception:
        pass
    # 2) BeautifulSoup ê¸°ë°˜ íŒŒì‹± ì‹œë„
    try:
        candidates = soup.find_all('table')
        best_bs: tuple[int,int,int,pd.DataFrame] | None = None
        for i, table in enumerate(candidates):
            rows = []
            for tr in table.find_all('tr'):
                cells = tr.find_all(['th','td'])
                if not cells:
                    continue
                rows.append([c.get_text(strip=True) for c in cells])
            if len(rows) < 3:
                continue
            df = pd.DataFrame(rows[1:], columns=rows[0])
            max_col_hits, total_hits = _score_table_for_teams(df)
            if best_bs is None or (max_col_hits, total_hits) > (best_bs[0], best_bs[1]):
                best_bs = (max_col_hits, total_hits, i, df)
        if best_bs and (best_bs[0] >= 5 or best_bs[1] >= 10):
            return best_bs[3]
    except Exception:
        pass
    return None

def _find_team_col_index(df: pd.DataFrame) -> int | None:
    tokens = _candidate_team_tokens()
    best_idx = None
    best_hits = -1
    for i, col in enumerate(df.columns):
        try:
            s = df[col].astype(str)
            hits = 0
            for tok in tokens:
                try:
                    hits += int(s.str.contains(tok, na=False).sum())
                except Exception:
                    continue
            if hits > best_hits:
                best_hits = hits
                best_idx = i
        except Exception:
            continue
    return best_idx if best_hits >= 5 else None

def _ensure_team_first_column(df: pd.DataFrame) -> pd.DataFrame:
    """íŒ€ëª…ì´ í¬í•¨ëœ ì—´ì„ ì°¾ì•„ 0ë²ˆì§¸ë¡œ ì´ë™í•˜ê³  í—¤ë”ë¥¼ ì •ë¦¬."""
    if df is None or df.empty:
        return df
    # í—¤ë” í–‰ì´ ë‚´ë¶€ì— ì¤‘ë³µë  ìˆ˜ ìˆì–´ ì œê±°
    try:
        header_set = set(map(str, df.columns))
        mask_header_like = df.apply(lambda r: set(map(str, r.values)) == header_set, axis=1)
        if mask_header_like.any():
            df = df.loc[~mask_header_like].reset_index(drop=True)
    except Exception:
        pass
    idx = _find_team_col_index(df)
    if idx is None:
        return df
    if idx != 0:
        cols = list(df.columns)
        new_cols = [cols[idx]] + cols[:idx] + cols[idx+1:]
        df = df[new_cols].copy()
    return df

def _drop_rank_like_columns(df: pd.DataFrame, team_col_index: int = 0) -> pd.DataFrame:
    """ìˆœìœ„ ì—´ ì œê±°(íŒ€ëª… ì—´ ì œì™¸).
    ì¡°ê±´:
    - í—¤ë”ì— 'ìˆœìœ„' ë˜ëŠ” 'ìˆœ'ì´ ëª…ì‹œëœ ê²½ìš°
    - ë˜ëŠ” í•´ë‹¹ ì—´ì˜ ìœ íš¨ ìˆ«ìê°’ì´ ì •í™•íˆ 1..N í˜•íƒœ(ì¤‘ë³µ ì—†ì´ ì „ì²´ ê¸¸ì´ì™€ ë™ì¼)
    """
    try:
        cols = list(df.columns)
        drop_indices: list[int] = []
        for i, col in enumerate(cols):
            if i == team_col_index:
                continue
            cname = str(col)
            if 'ìˆœìœ„' in cname or cname.strip() in ('ìˆœ', 'ìˆœë²ˆ', 'ë­í‚¹'):
                drop_indices.append(i)
                continue
            try:
                s = pd.to_numeric(df.iloc[:, i], errors='coerce')
                non_na = s.dropna()
                # ì •í™•íˆ 1..N í˜•íƒœì¸ì§€ íŒë‹¨
                if len(non_na) > 0 and (non_na % 1 == 0).all():
                    uniq = sorted(non_na.astype(int).unique().tolist())
                    expected = list(range(1, len(df) + 1))
                    if uniq == expected:
                        drop_indices.append(i)
            except Exception:
                continue
        if drop_indices:
            keep = [j for j in range(len(cols)) if j not in set(drop_indices)]
            df = df.iloc[:, keep].copy()
        return df
    except Exception:
        return df

def _normalize_standings_df(df: pd.DataFrame) -> pd.DataFrame:
    """ìˆœìœ„ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ì„ í‘œì¤€ ìˆœì„œë¡œ ì¬ë°°ì¹˜í•˜ê³  'ìˆœìœ„'ì²˜ëŸ¼ ë¶ˆí•„ìš”í•œ ë­í¬ì—´ì€ ì œê±°.
    íƒ€ê²Ÿ ìˆœì„œ: íŒ€ëª…, ê²½ê¸°, ìŠ¹, íŒ¨, ë¬´, ìŠ¹ë¥ , ê²Œì„ì°¨, ìµœê·¼10ê²½ê¸°
    """
    if df is None or df.empty:
        return df
    # íŒ€ëª… ì—´ì„ ì•ìœ¼ë¡œ ë³´ì¥
    df = _ensure_team_first_column(df)
    # ìˆœìœ„ ìœ ì‚¬ ì—´ ì œê±°
    df = _drop_rank_like_columns(df, team_col_index=0)
    # ì»¬ëŸ¼ëª… ì •ê·œí™”
    def norm(s: str) -> str:
        return re.sub(r"\s+", "", str(s))
    colmap = {i: norm(c) for i, c in enumerate(df.columns)}
    want = {
        'íŒ€ëª…': ['íŒ€ëª…', 'íŒ€', 'êµ¬ë‹¨'],
        'ê²½ê¸°': ['ê²½ê¸°', 'G', 'ê²Œì„ìˆ˜'],
        'ìŠ¹': ['ìŠ¹', 'W'],
        'íŒ¨': ['íŒ¨', 'L'],
        'ë¬´': ['ë¬´', 'D', 'T', 'ë¬´ìŠ¹ë¶€'],
        'ìŠ¹ë¥ ': ['ìŠ¹ë¥ ', 'WPCT'],
        'ê²Œì„ì°¨': ['ê²Œì„ì°¨', 'GB'],
        'ìµœê·¼10ê²½ê¸°': ['ìµœê·¼10ê²½ê¸°', 'ìµœê·¼10'],
    }
    found: dict[str, int | None] = {k: None for k in want}
    for target, keys in want.items():
        for idx, cname in colmap.items():
            if any(k in cname for k in keys):
                found[target] = idx
                break
    # í•„ìˆ˜: íŒ€ëª…, ê²½ê¸°, ìŠ¹, íŒ¨, ìŠ¹ë¥ 
    essential = ['íŒ€ëª…', 'ê²½ê¸°', 'ìŠ¹', 'íŒ¨', 'ìŠ¹ë¥ ']
    if any(found[k] is None for k in essential):
        return df
    order = [found['íŒ€ëª…'], found['ê²½ê¸°'], found['ìŠ¹'], found['íŒ¨'], found['ë¬´'], found['ìŠ¹ë¥ '], found['ê²Œì„ì°¨'], found['ìµœê·¼10ê²½ê¸°']]
    order = [i for i in order if i is not None]
    df2 = df.iloc[:, order].copy()
    # ì»¬ëŸ¼ëª… ë¶€ì—¬
    cols_final = ['íŒ€ëª…', 'ê²½ê¸°', 'ìŠ¹', 'íŒ¨']
    if found['ë¬´'] is not None:
        cols_final.append('ë¬´')
    cols_final += ['ìŠ¹ë¥ ']
    if found['ê²Œì„ì°¨'] is not None:
        cols_final.append('ê²Œì„ì°¨')
    if found['ìµœê·¼10ê²½ê¸°'] is not None:
        cols_final.append('ìµœê·¼10ê²½ê¸°')
    df2.columns = cols_final
    return df2

def _standardize_kbo_team_name(raw_name: str) -> str | None:
    """í˜ì´ì§€ë§ˆë‹¤ ë‹¤ë¥¸ íŒ€ëª… í‘œê¸°ë¥¼ í‘œì¤€ íŒ€ëª…ìœ¼ë¡œ í†µì¼.
    ì˜ˆ: 'SSGëœë”ìŠ¤' â†’ 'SSG', 'í‚¤ì›€íˆì–´ë¡œì¦ˆ' â†’ 'í‚¤ì›€', 'ê¸°ì•„' â†’ 'KIA' ë“±
    """
    if raw_name is None:
        return None
    name = str(raw_name)
    name = re.sub(r"\s+", "", name)
    upper = name.upper()
    # ëª…í™•í•œ í† í° ìš°ì„ 
    if 'LG' in upper:
        return 'LG'
    if 'DOOSAN' in upper or 'ë‘ì‚°' in name:
        return 'ë‘ì‚°'
    if 'SAMSUNG' in upper or 'ì‚¼ì„±' in name:
        return 'ì‚¼ì„±'
    if 'LOTTE' in upper or 'ë¡¯ë°' in name:
        return 'ë¡¯ë°'
    if 'HANHWA' in upper or 'í•œí™”' in name:
        return 'í•œí™”'
    if 'NC' in upper:
        return 'NC'
    if 'KT' in upper:
        return 'KT'
    if 'SSG' in upper or 'ëœë”ìŠ¤' in name:
        return 'SSG'
    if 'KIWOOM' in upper or 'í‚¤ì›€' in name:
        return 'í‚¤ì›€'
    if 'KIA' in upper or 'ê¸°ì•„' in name:
        return 'KIA'
    return None

def _fuzzy_map_team_name(raw_name: str) -> str | None:
    """ëŠìŠ¨í•œ ê¸°ì¤€ìœ¼ë¡œ íŒ€ëª…ì„ í‘œì¤€ íŒ€ëª…ìœ¼ë¡œ ë§¤í•‘.
    - TEAM_NAMES ë˜ëŠ” ëŒ€í‘œ í† í°ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë§¤í•‘
    - ì˜ˆ: 'ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆ' â†’ 'ì‚¼ì„±', 'KT ìœ„ì¦ˆ' â†’ 'KT'
    """
    if raw_name is None:
        return None
    s = str(raw_name)
    s_compact = re.sub(r"\s+", "", s)
    # ì§ì ‘ í‘œì¤€í™” ë¨¼ì €
    std = _standardize_kbo_team_name(s_compact)
    if std:
        return std
    # í¬í•¨ ê´€ê³„ë¡œ ë§¤í•‘
    synonyms = {
        'ë¡¯ë°': ['ë¡¯ë°', 'ìì´ì–¸ì¸ ', 'LOTTE'],
        'ì‚¼ì„±': ['ì‚¼ì„±', 'ë¼ì´ì˜¨ì¦ˆ', 'SAMSUNG'],
        'LG': ['LG', 'íŠ¸ìœˆìŠ¤'],
        'í•œí™”': ['í•œí™”', 'ì´ê¸€ìŠ¤', 'HANHWA'],
        'KIA': ['KIA', 'ê¸°ì•„', 'íƒ€ì´ê±°ì¦ˆ'],
        'ë‘ì‚°': ['ë‘ì‚°', 'ë² ì–´ìŠ¤', 'DOOSAN'],
        'NC': ['NC', 'ë‹¤ì´ë…¸ìŠ¤'],
        'KT': ['KT', 'ìœ„ì¦ˆ'],
        'SSG': ['SSG', 'ëœë”ìŠ¤'],
        'í‚¤ì›€': ['í‚¤ì›€', 'íˆì–´ë¡œì¦ˆ', 'KIWOOM'],
    }
    upper = s_compact.upper()
    for std_name, keys in synonyms.items():
        for key in keys:
            if key.upper() in upper:
                return std_name
    return None

# -----------------------------
# ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
# -----------------------------
@st.cache_data(ttl=3600)
def scrape_kbo_team_batting_stats():
    url = "https://www.koreabaseball.com/Record/Team/Hitter/Basic1.aspx"
    raw, soup = _first_table_html(url)
    df = _ensure_team_first_column(raw) if raw is not None else None
    if df is None or df.empty:
        # ìµœí›„ì˜ ë³´ë£¨: soupì—ì„œ ë² ìŠ¤íŠ¸ í…Œì´ë¸” ì¬ì„ íƒ
        _, soup2 = _first_table_html(url)
        if soup2 is not None:
            best = _choose_best_table_from_html(StringIO(soup2.text).getvalue() if hasattr(soup2, 'text') else '', soup2)
            if best is not None and not best.empty:
                df = _ensure_team_first_column(best)
        if df is None or df.empty:
            st.error("íƒ€ì ê¸°ë³¸ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    # ìˆœìœ„ ìœ ì‚¬ ì—´ ì œê±°ë¡œ ì»¬ëŸ¼ ì‹œí”„íŠ¸ ë°©ì§€
    df = _drop_rank_like_columns(df, team_col_index=0)
    # íŒ€ëª… í‘œì¤€í™” í›„ í•„í„°ë§
    try:
        df.iloc[:, 0] = df.iloc[:, 0].apply(lambda x: _standardize_kbo_team_name(x) or _fuzzy_map_team_name(x))
    except Exception:
        pass
    df = df[df.iloc[:, 0].isin(TEAM_NAMES)].copy()
    if df.empty:
        st.error("íƒ€ì ê¸°ë³¸ ê¸°ë¡ í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨(íŒ€ëª… í•„í„° ê²°ê³¼ 0í–‰). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    cols = ['íŒ€ëª…','AVG','G','PA','AB','R','H','2B','3B','HR','TB','RBI','SAC','SF']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    for c in df.columns:
        if c != 'íŒ€ëª…':
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('AVG', ascending=False).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', pd.Series(range(1, len(df)+1), dtype='Int64'))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_team_batting_stats_advanced():
    url = "https://www.koreabaseball.com/Record/Team/Hitter/Basic2.aspx"
    raw, soup = _first_table_html(url)
    df = _ensure_team_first_column(raw) if raw is not None else None
    if df is None or df.empty:
        _, soup2 = _first_table_html(url)
        if soup2 is not None:
            best = _choose_best_table_from_html(StringIO(soup2.text).getvalue() if hasattr(soup2, 'text') else '', soup2)
            if best is not None and not best.empty:
                df = _ensure_team_first_column(best)
        if df is None or df.empty:
            st.error("íƒ€ì ê³ ê¸‰ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    df = _drop_rank_like_columns(df, team_col_index=0)
    try:
        df.iloc[:, 0] = df.iloc[:, 0].apply(lambda x: _standardize_kbo_team_name(x) or _fuzzy_map_team_name(x))
    except Exception:
        pass
    df = df[df.iloc[:, 0].isin(TEAM_NAMES)].copy()
    if df.empty:
        st.error("íƒ€ì ê³ ê¸‰ ê¸°ë¡ í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨(íŒ€ëª… í•„í„° ê²°ê³¼ 0í–‰). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    cols = ['íŒ€ëª…','AVG','BB','IBB','HBP','SO','GDP','SLG','OBP','OPS','MH','RISP']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    for c in df.columns:
        if c != 'íŒ€ëª…':
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('AVG', ascending=False).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', pd.Series(range(1, len(df)+1), dtype='Int64'))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_team_pitching_stats():
    url = "https://www.koreabaseball.com/Record/Team/Pitcher/Basic1.aspx"
    raw, soup = _first_table_html(url)
    df = _ensure_team_first_column(raw) if raw is not None else None
    if df is None or df.empty:
        _, soup2 = _first_table_html(url)
        if soup2 is not None:
            best = _choose_best_table_from_html(StringIO(soup2.text).getvalue() if hasattr(soup2, 'text') else '', soup2)
            if best is not None and not best.empty:
                df = _ensure_team_first_column(best)
        if df is None or df.empty:
            st.error("íˆ¬ìˆ˜ ê¸°ë³¸ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    df = _drop_rank_like_columns(df, team_col_index=0)
    try:
        df.iloc[:, 0] = df.iloc[:, 0].apply(lambda x: _standardize_kbo_team_name(x) or _fuzzy_map_team_name(x))
    except Exception:
        pass
    df = df[df.iloc[:, 0].isin(TEAM_NAMES)].copy()
    if df.empty:
        st.error("íˆ¬ìˆ˜ ê¸°ë³¸ ê¸°ë¡ í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨(íŒ€ëª… í•„í„° ê²°ê³¼ 0í–‰). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    cols = ['íŒ€ëª…','ERA','G','W','L','SV','HLD','WPCT','IP','H','HR','BB','HBP','SO','R','ER','WHIP']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    if 'IP' in df.columns:
        df['IP_decimal'] = df['IP'].apply(_parse_ip_to_decimal)
        df['IP'] = df['IP'].astype(str)
    for c in df.columns:
        if c not in ['íŒ€ëª…','IP']:
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('ERA', ascending=True).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', pd.Series(range(1, len(df)+1), dtype='Int64'))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_team_pitching_stats_advanced():
    url = "https://www.koreabaseball.com/Record/Team/Pitcher/Basic2.aspx"
    raw, soup = _first_table_html(url)
    df = _ensure_team_first_column(raw) if raw is not None else None
    if df is None or df.empty:
        _, soup2 = _first_table_html(url)
        if soup2 is not None:
            best = _choose_best_table_from_html(StringIO(soup2.text).getvalue() if hasattr(soup2, 'text') else '', soup2)
            if best is not None and not best.empty:
                df = _ensure_team_first_column(best)
        if df is None or df.empty:
            st.error("íˆ¬ìˆ˜ ê³ ê¸‰ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    df = _drop_rank_like_columns(df, team_col_index=0)
    try:
        df.iloc[:, 0] = df.iloc[:, 0].apply(lambda x: _standardize_kbo_team_name(x) or _fuzzy_map_team_name(x))
    except Exception:
        pass
    df = df[df.iloc[:, 0].isin(TEAM_NAMES)].copy()
    if df.empty:
        st.error("íˆ¬ìˆ˜ ê³ ê¸‰ ê¸°ë¡ í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨(íŒ€ëª… í•„í„° ê²°ê³¼ 0í–‰). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    cols = ['íŒ€ëª…','ERA','CG','SHO','QS','BSV','TBF','NP','AVG','2B','3B','SAC','SF','IBB','WP','BK']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    for c in df.columns:
        if c != 'íŒ€ëª…':
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('ERA', ascending=True).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', pd.Series(range(1, len(df)+1), dtype='Int64'))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_standings():
    url = "https://www.koreabaseball.com/Record/TeamRank/TeamRankDaily.aspx"
    raw, soup = _first_table_html(url)
    df = _ensure_team_first_column(raw) if raw is not None else None
    date_info = None
    if soup:
        all_texts = soup.get_text("\n")
        m = re.search(r"\(\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼\s*ê¸°ì¤€\)", all_texts)
        if m:
            date_info = m.group(0)
    if df is None or df.empty:
        _, soup2 = _first_table_html(url)
        if soup2 is not None:
            best = _choose_best_table_from_html(StringIO(soup2.text).getvalue() if hasattr(soup2, 'text') else '', soup2)
            if best is not None and not best.empty:
                df = _ensure_team_first_column(best)
        if df is None or df.empty:
            st.error("ìˆœìœ„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, date_info
    # ì»¬ëŸ¼ êµ¬ì¡° ì •ê·œí™” ë° íŒ€ëª… í‘œì¤€í™”
    df = _normalize_standings_df(df)
    try:
        df.iloc[:, 0] = df.iloc[:, 0].apply(lambda x: _standardize_kbo_team_name(x) or _fuzzy_map_team_name(x))
    except Exception:
        pass
    df = df[df.iloc[:, 0].isin(['LG','í•œí™”','ë¡¯ë°','ì‚¼ì„±','SSG','NC','KIA','ë‘ì‚°','KT','í‚¤ì›€'])].copy()
    for c in ['ê²½ê¸°','ìŠ¹','íŒ¨','ë¬´','ìŠ¹ë¥ ']:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')
    # ë¬´ìŠ¹ë¶€ ë³´ì •: ì›ë³¸ì— ì—†ê±°ë‚˜ ê²°ì¸¡ì´ë©´ ê²½ê¸°-ìŠ¹-íŒ¨ë¡œ ê³„ì‚°
    try:
        if 'ë¬´' not in df.columns:
            df['ë¬´'] = (df['ê²½ê¸°'] - df['ìŠ¹'] - df['íŒ¨']).clip(lower=0)
        else:
            null_mask = df['ë¬´'].isna()
            if null_mask.any():
                df.loc[null_mask, 'ë¬´'] = (df.loc[null_mask, 'ê²½ê¸°'] - df.loc[null_mask, 'ìŠ¹'] - df.loc[null_mask, 'íŒ¨']).clip(lower=0)
    except Exception:
        pass
    # ì»¬ëŸ¼ ì¬ì •ë ¬(ë¬´ í¬í•¨ ë³´ì¥)
    try:
        desired = [col for col in ['íŒ€ëª…','ê²½ê¸°','ìŠ¹','íŒ¨','ë¬´','ìŠ¹ë¥ ','ê²Œì„ì°¨','ìµœê·¼10ê²½ê¸°'] if col in df.columns]
        df = df[desired + [c for c in df.columns if c not in desired]]
    except Exception:
        pass
    df = df.sort_values('ìŠ¹ë¥ ', ascending=False).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', pd.Series(range(1, len(df)+1), dtype='Int64'))
    return df, date_info

# -----------------------------
# ì‹œë®¬ë ˆì´ì…˜(ê³ ì†/ì•ˆì „)
# -----------------------------
def monte_carlo_expected_wins(p: float, n_games: int, n_sims: int = 10_000) -> float:
    if n_games <= 0:
        return 0.0
    if p <= 0.0:
        return 0.0
    if p >= 1.0:
        return float(n_games)
    wins = np.random.binomial(n=n_games, p=float(p), size=n_sims)
    return float(wins.mean())

def calculate_championship_probability(teams_df: pd.DataFrame, num_simulations: int = 100_000) -> dict:
    """
    í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥  ê¸°ë°˜ ìš°ìŠ¹ í™•ë¥  ê³„ì‚°(ë¹ˆ DF/íŒ€ ìˆ˜ 0/ì”ì—¬ê²½ê¸° 0 ì „ë¶€ ë°©ì–´).
    """
    if teams_df is None or teams_df.empty:
        st.warning("ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒ íŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    required = {"íŒ€ëª…", "ìŠ¹", "p_wpct", "ì”ì—¬ê²½ê¸°"}
    missing = [c for c in required if c not in teams_df.columns]
    if missing:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing)}")
        return {}

    df = teams_df.copy()
    # íƒ€ì… ì •ë¦¬
    df["ì”ì—¬ê²½ê¸°"] = pd.to_numeric(df["ì”ì—¬ê²½ê¸°"], errors="coerce").fillna(0).astype(int).clip(lower=0)
    df["ìŠ¹"] = pd.to_numeric(df["ìŠ¹"], errors="coerce").fillna(0).astype(int)
    df["p_wpct"] = pd.to_numeric(df["p_wpct"], errors="coerce").fillna(0.0).astype(float)

    # íŒ€ëª… ì •ê·œí™”
    df = normalize_team_names(df)

    # ìœ íš¨ íŒ€ë§Œ(ìˆ˜ì¹˜í˜• NaN ì œê±°)
    df = df.loc[df["p_wpct"].notna() & df["ìŠ¹"].notna() & df["ì”ì—¬ê²½ê¸°"].notna()].reset_index(drop=True)
    T = len(df)
    if T == 0:
        st.warning("ìœ íš¨í•œ íŒ€ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return {}

    names = df["íŒ€ëª…"].tolist()
    current_wins = df["ìŠ¹"].to_numpy(dtype=int)
    p = df["p_wpct"].to_numpy(dtype=float)
    n_remain = df["ì”ì—¬ê²½ê¸°"].to_numpy(dtype=int)

    # ì”ì—¬ê²½ê¸° ì „ì²´ 0ì¸ ê²½ìš°: í˜„ì¬ ìŠ¹ìˆ˜ ê¸°ì¤€
    if np.all(n_remain == 0):
        winners = {n: 0.0 for n in names}
        try:
            if len(current_wins) > 0:
                winners[names[int(np.argmax(current_wins))]] = 100.0
        except ValueError:
            # ë¹ˆ ì‹œí€€ìŠ¤ ì•ˆì „ë§
            pass
        st.info("ëª¨ë“  íŒ€ì˜ ì”ì—¬ ê²½ê¸°ê°€ 0ì…ë‹ˆë‹¤. í˜„ì¬ ìŠ¹ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìš°ìŠ¹ í™•ë¥ ì„ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.")
        return winners

    wins_count = {n: 0 for n in names}
    prog = st.progress(0.0)
    text = st.empty()

    # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬/ì†ë„ ê· í˜•
    batch = 10_000
    n_batches = int(np.ceil(num_simulations / batch))

    for b in range(n_batches):
        this_batch = batch if (b + 1) * batch <= num_simulations else (num_simulations - b * batch)
        if this_batch <= 0:
            continue

        # (B, T) ë°°ì—´ì„ "ì—´(íŒ€)ë³„"ë¡œ ìƒì„± â†’ n,pê°€ ë²¡í„°ì—¬ë„ ì•ˆì „
        sim = np.empty((this_batch, T), dtype=int)
        for t in range(T):
            nt = int(n_remain[t]); pt = float(p[t])
            if nt <= 0 or pt <= 0.0:
                sim[:, t] = 0
            elif pt >= 1.0:
                sim[:, t] = nt
            else:
                sim[:, t] = np.random.binomial(n=nt, p=pt, size=this_batch)

        final_wins = sim + current_wins  # (B, T)
        if final_wins.size == 0 or final_wins.shape[1] == 0:
            # ì•ˆì „ë§: T==0 ë˜ëŠ” B==0
            continue

        try:
            idx = np.argmax(final_wins, axis=1)  # (B,)
        except ValueError:
            # ë¹ˆ ì‹œí€€ìŠ¤ ì•ˆì „ë§
            continue
        for i in idx:
            wins_count[names[int(i)]] += 1

        if b % 2 == 0:
            prog.progress((b + 1) / n_batches)
            text.text(f"ìš°ìŠ¹ í™•ë¥  ê³„ì‚° ì¤‘... {min((b + 1) * batch, num_simulations):,}/{num_simulations:,}")

    prog.progress(1.0)
    text.text("ìš°ìŠ¹ í™•ë¥  ê³„ì‚° ì™„ë£Œ!")
    return {k: v / num_simulations * 100.0 for k, v in wins_count.items()}

def calculate_playoff_probability(teams_df: pd.DataFrame, num_simulations: int = 50_000) -> dict:
    """
    ìƒìœ„ 5íŒ€ í”Œë ˆì´ì˜¤í”„ ì§„ì¶œ í™•ë¥ (ë¹ˆ DF/íŒ€ ìˆ˜ < 5/ì”ì—¬ê²½ê¸° 0 ë°©ì–´).
    """
    if teams_df is None or teams_df.empty:
        st.warning("ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒ íŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    required = {"íŒ€ëª…", "ìŠ¹", "p_wpct", "ì”ì—¬ê²½ê¸°"}
    missing = [c for c in required if c not in teams_df.columns]
    if missing:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing)}")
        return {}

    df = teams_df.copy()
    df["ì”ì—¬ê²½ê¸°"] = pd.to_numeric(df["ì”ì—¬ê²½ê¸°"], errors="coerce").fillna(0).astype(int).clip(lower=0)
    df["ìŠ¹"] = pd.to_numeric(df["ìŠ¹"], errors="coerce").fillna(0).astype(int)
    df["p_wpct"] = pd.to_numeric(df["p_wpct"], errors="coerce").fillna(0.0).astype(float)

    df = normalize_team_names(df)
    df = df.loc[df["p_wpct"].notna() & df["ìŠ¹"].notna() & df["ì”ì—¬ê²½ê¸°"].notna()].reset_index(drop=True)

    T = len(df)
    if T == 0:
        st.warning("ìœ íš¨í•œ íŒ€ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return {}

    names = df["íŒ€ëª…"].tolist()
    current_wins = df["ìŠ¹"].to_numpy(dtype=int)
    p = df["p_wpct"].to_numpy(dtype=float)
    n_remain = df["ì”ì—¬ê²½ê¸°"].to_numpy(dtype=int)

    top_k = min(5, T)
    po_counts = {n: 0 for n in names}
    prog = st.progress(0.0)
    text = st.empty()

    batch = 10_000
    n_batches = int(np.ceil(num_simulations / batch))

    for b in range(n_batches):
        this_batch = batch if (b + 1) * batch <= num_simulations else (num_simulations - b * batch)
        if this_batch <= 0:
            continue

        sim = np.empty((this_batch, T), dtype=int)
        for t in range(T):
            nt = int(n_remain[t]); pt = float(p[t])
            if nt <= 0 or pt <= 0.0:
                sim[:, t] = 0
            elif pt >= 1.0:
                sim[:, t] = nt
            else:
                sim[:, t] = np.random.binomial(n=nt, p=pt, size=this_batch)

        final_wins = sim + current_wins
        if final_wins.size == 0 or final_wins.shape[1] == 0:
            continue

        # ë¹ ë¥¸ ìƒìœ„ ì„ íƒ
        try:
            topk_idx = np.argpartition(-final_wins, kth=top_k - 1, axis=1)[:, :top_k]
        except ValueError:
            # ë¹ˆ ë°°ì—´ ì•ˆì „ë§
            continue
        rows = np.arange(final_wins.shape[0])[:, None]
        ordered = topk_idx[rows, np.argsort(-final_wins[rows, topk_idx], axis=1)]

        for row in ordered:
            for i in row:
                po_counts[names[int(i)]] += 1

        if b % 2 == 0:
            prog.progress((b + 1) / n_batches)
            text.text(f"í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì¤‘... {min((b + 1) * batch, num_simulations):,}/{num_simulations:,}")

    prog.progress(1.0)
    text.text("í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì™„ë£Œ!")
    return {k: v / num_simulations * 100.0 for k, v in po_counts.items()}

def _validate_sim_inputs(df_final: pd.DataFrame) -> bool:
    """ì‹œë®¬ ì‹œì‘ ì „ ì…ë ¥ ê²€ì¦. ë¬¸ì œê°€ ìˆìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì›ì¸ í‘œì‹œí•˜ê³  False."""
    need = {"íŒ€ëª…", "ìŠ¹", "p_wpct", "ì”ì—¬ê²½ê¸°"}
    if df_final is None or df_final.empty:
        st.error("ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤(df_final).")
        return False
    miss = [c for c in need if c not in df_final.columns]
    if miss:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(miss)}")
        return False
    if df_final["íŒ€ëª…"].isna().all():
        st.error("íŒ€ëª… ì»¬ëŸ¼ì´ ë¹„ì–´ ìˆì–´ ì‹œë®¬ë ˆì´ì…˜ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    return True

# -----------------------------
# ë©”ì¸
# -----------------------------
def main():
    st.markdown('<h1 class="main-header">âš¾ KBO íŒ€ í†µê³„ ë¶„ì„ê¸°</h1>', unsafe_allow_html=True)

    # ë°ì´í„° ë¡œë”©
    with st.spinner("ì‹¤ì‹œê°„ KBO ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        df_hitter = scrape_kbo_team_batting_stats()
        df_hitter_adv = scrape_kbo_team_batting_stats_advanced()
        df_pitcher = scrape_kbo_team_pitching_stats()
        df_pitcher_adv = scrape_kbo_team_pitching_stats_advanced()
        df_standings, date_info = scrape_kbo_standings()

    if any(x is None for x in [df_hitter, df_hitter_adv, df_pitcher, df_pitcher_adv, df_standings]):
        st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return

    # íŒ€ëª… ì •ê·œí™”(ë³‘í•© ì „)
    df_hitter = normalize_team_names(df_hitter)
    df_hitter_adv = normalize_team_names(df_hitter_adv)
    df_pitcher = normalize_team_names(df_pitcher)
    df_pitcher_adv = normalize_team_names(df_pitcher_adv)
    df_standings = normalize_team_names(df_standings)

    if date_info:
        st.markdown(
            f'<p style="text-align:center;font-size:1rem;color:#666;margin-top:-1rem;margin-bottom:2rem;">{date_info}</p>',
            unsafe_allow_html=True
        )

    # ê²°í•©
    df_hitter_combined = pd.merge(
        df_hitter,
        df_hitter_adv[['íŒ€ëª…','BB','IBB','HBP','SO','GDP','SLG','OBP','OPS','MH','RISP']],
        on='íŒ€ëª…', how='left'
    )
    # íƒ€ì í‘œì— ë“ì  Rë„ í¬í•¨ë˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìœ ì§€
    df_pitcher_combined = pd.merge(
        df_pitcher,
        df_pitcher_adv[['íŒ€ëª…','CG','SHO','QS','BSV','TBF','NP','AVG','2B','3B','SAC','SF','IBB','WP','BK']],
        on='íŒ€ëª…', how='left'
    )

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ˆ í˜„ì¬ ìˆœìœ„", "ğŸŸï¸ íŒ€ë³„ ê¸°ë¡", "ğŸ“Š ì‹œê°í™”", "ğŸ† ìš°ìŠ¹í™•ë¥ ", "ğŸ“… íˆìŠ¤í† ë¦¬"])

    with tab1:
        # í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥  ê³„ì‚°
        df_runs = pd.merge(
            df_hitter[['íŒ€ëª…','R']],
            df_pitcher[['íŒ€ëª…','R']].rename(columns={'R': 'RA'}),
            on='íŒ€ëª…', how='left'
        )
        p_n = 1.834
        df_runs['p_wpct'] = (df_runs['R']**p_n) / ((df_runs['R']**p_n) + (df_runs['RA']**p_n))
        df_runs['p_wpct'] = df_runs['p_wpct'].round(4)

        # ë“ì (R), ì‹¤ì (RA), í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥ ì„ ëª¨ë‘ ê²°í•©
        df_final = pd.merge(df_standings, df_runs[['íŒ€ëª…','R','RA','p_wpct']], on='íŒ€ëª…', how='left')
        df_final['ì”ì—¬ê²½ê¸°'] = (144 - df_final['ê²½ê¸°']).clip(lower=0)

        # ê¸°ë³¸ ê¸°ëŒ€ìŠ¹ìˆ˜
        np.random.seed(42)
        df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜'] = [
            monte_carlo_expected_wins(
                p=float(r['ìŠ¹ë¥ ']) if pd.notna(r['ìŠ¹ë¥ ']) else 0.0,
                n_games=int(r['ì”ì—¬ê²½ê¸°']) if pd.notna(r['ì”ì—¬ê²½ê¸°']) else 0,
                n_sims=100_000
            )
            for _, r in df_final.iterrows()
        ]
        df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜'] = [
            monte_carlo_expected_wins(
                p=float(r['p_wpct']) if pd.notna(r['p_wpct']) else 0.0,
                n_games=int(r['ì”ì—¬ê²½ê¸°']) if pd.notna(r['ì”ì—¬ê²½ê¸°']) else 0,
                n_sims=100_000
            )
            for _, r in df_final.iterrows()
        ]
        df_final['ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜'] = (df_final['ìŠ¹'] + df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜']).round(1)
        df_final['ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜'] = (df_final['ìŠ¹'] + df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜']).round(1)

        st.session_state['df_final'] = df_final.copy()

        # st.subheader("ğŸ“Š í˜„ì¬ ìˆœìœ„ ë° ì˜ˆì¸¡ ë¶„ì„")
        # í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ê°’ìœ¼ë¡œ ì±„ì›Œ ì•ˆì „í•˜ê²Œ í‘œì‹œ
        _needed = ['ìˆœìœ„','íŒ€ëª…','ê²½ê¸°','ìŠ¹','íŒ¨','ë¬´','ìŠ¹ë¥ ','ê²Œì„ì°¨','ìµœê·¼10ê²½ê¸°','R','RA','p_wpct','ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜']
        for _c in _needed:
            if _c not in df_final.columns:
                df_final[_c] = pd.NA
        display = df_final[_needed].copy()
        display.rename(columns={'p_wpct':'í”¼íƒ€ê³ ë¦¬ì•ˆ','ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜':'ì˜ˆìƒìŠ¹ìˆ˜'}, inplace=True)
        display['í”¼íƒ€ê³ ë¦¬ì•ˆ'] = display['í”¼íƒ€ê³ ë¦¬ì•ˆ'].round(4)
        safe_dataframe_display(clean_dataframe_for_display(display), use_container_width=True, hide_index=True)
        st.caption(f"ì›ë³¸ ë°ì´í„°: [KBO íŒ€ ìˆœìœ„]({KBO_URLS['standings']})  |  [íƒ€ì ê¸°ë³¸]({KBO_URLS['hitter_basic1']})  |  [íˆ¬ìˆ˜ ê¸°ë³¸]({KBO_URLS['pitcher_basic1']})")

        with st.expander("ğŸ” ë°ì´í„° ìˆ˜ì§‘ ë””ë²„ê·¸", expanded=False):
            try:
                st.write({
                    'íƒ€ìê¸°ë³¸': None if df_hitter is None else df_hitter.shape,
                    'íƒ€ìê³ ê¸‰': None if df_hitter_adv is None else df_hitter_adv.shape,
                    'íˆ¬ìˆ˜ê¸°ë³¸': None if df_pitcher is None else df_pitcher.shape,
                    'íˆ¬ìˆ˜ê³ ê¸‰': None if df_pitcher_adv is None else df_pitcher_adv.shape,
                    'ìˆœìœ„': None if df_standings is None else df_standings.shape,
                })
                dbg_cols = st.columns(4)
                with dbg_cols[0]:
                    st.caption('íƒ€ìê¸°ë³¸ head'); st.write(None if df_hitter is None else df_hitter.head())
                with dbg_cols[1]:
                    st.caption('íƒ€ìê³ ê¸‰ head'); st.write(None if df_hitter_adv is None else df_hitter_adv.head())
                with dbg_cols[2]:
                    st.caption('íˆ¬ìˆ˜ê¸°ë³¸ head'); st.write(None if df_pitcher is None else df_pitcher.head())
                with dbg_cols[3]:
                    st.caption('íˆ¬ìˆ˜ê³ ê¸‰ head'); st.write(None if df_pitcher_adv is None else df_pitcher_adv.head())
                # with dbg_cols[4]:
                st.caption('ìˆœìœ„ head'); st.write(None if df_standings is None else df_standings.head())
            except Exception as e:
                st.write(f"ë””ë²„ê·¸ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {e}")

    with tab2:
        # st.header("ğŸŸï¸ íŒ€ë³„ ê¸°ë¡")
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("íƒ€ì ê¸°ë¡")
            safe_dataframe_display(clean_dataframe_for_display(df_hitter_combined), True, True)
            st.caption(f"ì›ë³¸ ë°ì´í„°: [íƒ€ì ê¸°ë³¸]({KBO_URLS['hitter_basic1']}) Â· [íƒ€ì ê³ ê¸‰]({KBO_URLS['hitter_basic2']})")
        with c2:
            st.subheader("íˆ¬ìˆ˜ ê¸°ë¡")
            safe_dataframe_display(clean_dataframe_for_display(df_pitcher_combined), True, True)
            st.caption(f"ì›ë³¸ ë°ì´í„°: [íˆ¬ìˆ˜ ê¸°ë³¸]({KBO_URLS['pitcher_basic1']}) Â· [íˆ¬ìˆ˜ ê³ ê¸‰]({KBO_URLS['pitcher_basic2']})")

        st.subheader("ğŸ† TOP 3 íŒ€")
        l, r = st.columns(2)
        with l:
            st.subheader("íƒ€ê²© ìƒìœ„ 3íŒ€")
            top3_avg = df_hitter_combined.nlargest(3, 'AVG')[['íŒ€ëª…','AVG']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in top3_avg.iterrows():
                cols[i].metric(f"{i+1}ìœ„ {row['íŒ€ëª…']}", f"{row['AVG']:.3f}")
            st.write("**OPS ìƒìœ„ 3íŒ€**")
            top3_ops = df_hitter_combined.nlargest(3, 'OPS')[['íŒ€ëª…','OPS']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in top3_ops.iterrows():
                cols[i].metric(f"{i+1}ìœ„ {row['íŒ€ëª…']}", f"{row['OPS']:.3f}")
        with r:
            st.subheader("íˆ¬ìˆ˜ ìƒìœ„ 3íŒ€")
            st.write("**ERA ìƒìœ„ 3íŒ€ (ë‚®ì€ ìˆœ)**")
            top3_era = df_pitcher_combined.nsmallest(3, 'ERA')[['íŒ€ëª…','ERA']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in enumerate(top3_era.itertuples(index=False)):
                cols[i].metric(f"{i+1}ìœ„ {row.íŒ€ëª…}", f"{row.ERA:.2f}")
            st.write("**WHIP ìƒìœ„ 3íŒ€ (ë‚®ì€ ìˆœ)**")
            top3_whip = df_pitcher_combined.nsmallest(3, 'WHIP')[['íŒ€ëª…','WHIP']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in enumerate(top3_whip.itertuples(index=False)):
                cols[i].metric(f"{i+1}ìœ„ {row.íŒ€ëª…}", f"{row.WHIP:.2f}")

    with tab3:
        # st.header("ğŸ“Š ì‹œê°í™”")
        c1, c2 = st.columns(2)
        with c1:
            fig1 = px.scatter(df_hitter_combined, x='AVG', y='HR', title="íƒ€ìœ¨ vs í™ˆëŸ°", hover_data=['íŒ€ëª…'], text='íŒ€ëª…')
            fig1.update_traces(textposition="top center", marker_size=12)
            fig1.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig1.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            st.plotly_chart(fig1, use_container_width=True)
        with c2:
            fig2 = px.scatter(df_pitcher_combined, x='ERA', y='SO', title="ERA vs ì‚¼ì§„", hover_data=['íŒ€ëª…'], text='íŒ€ëª…')
            fig2.update_traces(textposition="top center", marker_size=12)
            fig2.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig2.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            st.plotly_chart(fig2, use_container_width=True)

        df_final = st.session_state['df_final']
        fig3 = px.scatter(df_final, x='ìŠ¹ë¥ ', y='p_wpct', 
                    title="ì‹¤ì œ ìŠ¹ë¥  vs í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥ ", hover_data=['íŒ€ëª…'], text='íŒ€ëª…')
        fig3.add_trace(go.Scatter(x=[0.25, 0.65], y=[0.25, 0.65], mode='lines', name='ê¸°ì¤€ì„ ',
                                  line=dict(dash='dash', color='red')))
        fig3.update_traces(textposition="middle left", marker_size=12)
        fig3.update_xaxes(range=[0.25, 0.65], showgrid=True, gridwidth=1, gridcolor='lightgray')
        fig3.update_yaxes(range=[0.25, 0.65], showgrid=True, gridwidth=1, gridcolor='lightgray')
        fig3.update_layout(showlegend=False)
        st.plotly_chart(fig3, use_container_width=True)
        
        st.caption(f"ì›ë³¸ ë°ì´í„°: [íƒ€ì ê¸°ë³¸]({KBO_URLS['hitter_basic1']}) Â· [íƒ€ì ê³ ê¸‰]({KBO_URLS['hitter_basic2']}) Â· [íˆ¬ìˆ˜ ê¸°ë³¸]({KBO_URLS['pitcher_basic1']}) Â· [íˆ¬ìˆ˜ ê³ ê¸‰]({KBO_URLS['pitcher_basic2']}) Â· [íŒ€ ìˆœìœ„]({KBO_URLS['standings']})")

    with tab4:
        df_final = st.session_state['df_final']
        c1, c2 = st.columns(2)
        with c1:
            championship_simulations = st.slider("ìš°ìŠ¹ í™•ë¥  ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", 50_000, 300_000, 100_000, step=10_000)
        with c2:
            playoff_simulations = st.slider("í”Œë ˆì´ì˜¤í”„ í™•ë¥  ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", 50_000, 300_000, 100_000, step=10_000)

        if st.button("ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
            with st.spinner("ìš°ìŠ¹/í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì¤‘..."):
                # ì…ë ¥ ê²€ì¦: ë¹„ì •ìƒ ì…ë ¥ì´ë©´ ì¤‘ë‹¨
                if not _validate_sim_inputs(df_final):
                    st.stop()

                champs = calculate_championship_probability(df_final, championship_simulations)
                df_final['ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸'] = df_final['íŒ€ëª…'].map(champs)
                po = calculate_playoff_probability(df_final, playoff_simulations)
                df_final['í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸'] = df_final['íŒ€ëª…'].map(po)

                log_df = df_final[['íŒ€ëª…','ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸','í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸']].copy()
                # ê¸°ì¤€ì¼ì€ ìˆœìœ„ í˜ì´ì§€ì—ì„œ ì¶”ì¶œí•œ date_info ì‚¬ìš©
                base_date = _parse_kbo_date_info_to_date(date_info) if date_info else None
                append_simulation_to_sheet(log_df, "SimulationLog", base_date=base_date)

                display_col = 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜' if 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜' in df_final.columns else 'ìŠ¹'
                combined = df_final[['ìˆœìœ„','íŒ€ëª…',display_col,'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸','í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸']].copy()
                combined.rename(columns={display_col:'ì˜ˆìƒìµœì¢…ìŠ¹ìˆ˜'}, inplace=True)
                combined = combined.sort_values('ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', ascending=False).reset_index(drop=True)

                # st.subheader("ğŸ† KBO ìš°ìŠ¹ í™•ë¥  & PO ì§„ì¶œ í™•ë¥ ")
                disp = clean_dataframe_for_display(combined).rename(
                    columns={'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸':'ìš°ìŠ¹í™•ë¥ ','í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸':'POí™•ë¥ '}
                )
                safe_dataframe_display(disp, True, True)

                cc1, cc2 = st.columns(2)
                with cc1:
                    fig = px.bar(combined, x='íŒ€ëª…', y='ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', title="íŒ€ë³„ ìš°ìŠ¹ í™•ë¥ ",
                                 color='ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', color_continuous_scale='RdYlGn')
                    try:
                        fig.update_traces(text=combined['ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸'], texttemplate='%{text:.3f}%', textposition='outside', cliponaxis=False)
                    except Exception:
                        pass
                    fig.update_layout(xaxis_tickangle=-45, showlegend=False, coloraxis_showscale=False)
                    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', range=[0,100], dtick=10, ticksuffix='%')
                    st.plotly_chart(fig, use_container_width=True)

                with cc2:
                    fig2 = px.bar(combined, x='íŒ€ëª…', y='í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸', title="íŒ€ë³„ í”Œë ˆì´ì˜¤í”„ ì§„ì¶œ í™•ë¥ ",
                                color='í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸', color_continuous_scale='Blues')
                    try:
                        fig2.update_traces(text=combined['í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸'], texttemplate='%{text:.2f}%', textposition='outside', cliponaxis=False)
                    except Exception:
                        pass
                    fig2.update_layout(xaxis_tickangle=-45, showlegend=False, coloraxis_showscale=False)
                    fig2.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                    fig2.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', range=[0,100], dtick=10, ticksuffix='%')
                    st.plotly_chart(fig2, use_container_width=True)
                st.caption(f"ì›ë³¸ ë°ì´í„°: [íŒ€ ìˆœìœ„]({KBO_URLS['standings']})")

        # Bradley-Terry ëª¨í˜• ê¸°ë°˜ ìˆœìœ„ ì˜ˆì¸¡ íˆíŠ¸ë§µ
        st.subheader("ğŸ”¥ Bradley-Terry ëª¨í˜• ìˆœìœ„ ì˜ˆì¸¡ íˆíŠ¸ë§µ")
        st.markdown("""
        **ë°©ë²•ë¡ **: íŒ€ê°„ ìƒëŒ€ ì „ì ì„ ê¸°ë°˜ìœ¼ë¡œ Bradley-Terry ëª¨í˜•ìœ¼ë¡œ íŒ€ ê°•ë„ë¥¼ ì¶”ì •í•˜ê³ , 
        ìƒëŒ€ë‹¹ 16ê²½ê¸° ê¸°ì¤€ ì”ì—¬ ì¼ì •ì„ 10ë§Œ íšŒ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ìµœì¢… ìˆœìœ„ ë¶„í¬ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        """)
        
        if st.button("Bradley-Terry ìˆœìœ„ ì˜ˆì¸¡ ì‹œì‘"):
            with st.spinner("Bradley-Terry ëª¨í˜•ìœ¼ë¡œ ìˆœìœ„ ì˜ˆì¸¡ ê³„ì‚° ì¤‘..."):
                try:
                    # 1) íŒ€ê°„ ìŠ¹íŒ¨í‘œ í¬ë¡¤ë§
                    url_vs = "https://www.koreabaseball.com/Record/TeamRank/TeamRankDaily.aspx"
                    raw_vs, soup_vs = _first_table_html(url_vs)
                    
                    if raw_vs is None or soup_vs is None:
                        st.error("íŒ€ê°„ ìŠ¹íŒ¨í‘œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    # ë‘ ë²ˆì§¸ í…Œì´ë¸”(íŒ€ê°„ ìŠ¹íŒ¨í‘œ) ì°¾ê¸°
                    tables = soup_vs.find_all("table")
                    if len(tables) < 2:
                        st.error("íŒ€ê°„ ìŠ¹íŒ¨í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    # ë‘ ë²ˆì§¸ í…Œì´ë¸” íŒŒì‹±
                    df_vs_raw = pd.read_html(str(tables[1]))[0]
                    
                    # 2) ë°ì´í„° ì •ê·œí™”
                    teams = df_final['íŒ€ëª…'].tolist()
                    n = len(teams)
                    idx = {t: i for i, t in enumerate(teams)}
                    
                    # íŒ€ê°„ ìŠ¹íŒ¨í‘œ ì •ê·œí™”
                    def normalize_tvt(df_vs, teams):
                        # ì»¬ëŸ¼ëª…ì—ì„œ íŒ€ëª…ë§Œ ì¶”ì¶œ (ì˜ˆ: "LG (ìŠ¹-íŒ¨-ë¬´)" -> "LG")
                        new_cols = []
                        for c in df_vs.columns:
                            col_str = str(c).strip()
                            if col_str == "íŒ€ëª…":
                                new_cols.append("íŒ€ëª…")
                            else:
                                # íŒ€ëª… ì¶”ì¶œ (ê´„í˜¸ ì•ë¶€ë¶„)
                                team_name = col_str.split(" (")[0].strip()
                                if team_name in teams:
                                    new_cols.append(team_name)
                                else:
                                    new_cols.append(col_str)
                        
                        df_vs.columns = new_cols
                        
                        # íŒ€ëª… ì»¬ëŸ¼ ì²˜ë¦¬
                        if "íŒ€ëª…" not in df_vs.columns:
                            df_vs.rename(columns={df_vs.columns[0]: "íŒ€ëª…"}, inplace=True)
                        df_vs["íŒ€ëª…"] = df_vs["íŒ€ëª…"].astype(str).str.strip()
                        
                        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                        available_teams = [t for t in teams if t in df_vs.columns]
                        cols = ["íŒ€ëª…"] + available_teams
                        df_vs = df_vs[[c for c in cols if c in df_vs.columns]].copy()
                        
                        # ë°ì´í„° ì •ë¦¬
                        for c in df_vs.columns[1:]:
                            df_vs[c] = df_vs[c].astype(str).str.replace(r"\s+", "", regex=True)
                        
                        return df_vs
                    
                    df_vs = normalize_tvt(df_vs_raw, teams)
                    
                    # ìŠ¹íŒ¨ë¬´ íŒŒì‹±
                    def parse_wlt(cell):
                        s = str(cell).strip()
                        if s in ["â– ", "-", "â€”", "â€“", "nan", "None", ""] or s.lower() == "nan":
                            return (np.nan, np.nan, np.nan)
                        parts = s.split("-")
                        try:
                            if len(parts) == 3:
                                return int(parts[0]), int(parts[1]), int(parts[2])
                            if len(parts) == 2:
                                return int(parts[0]), int(parts[1]), 0
                        except:
                            pass
                        return (np.nan, np.nan, np.nan)
                    
                    # ìŠ¹íŒ¨ë¬´ í–‰ë ¬ êµ¬ì„±
                    W = np.zeros((n, n), dtype=int)
                    L = np.zeros((n, n), dtype=int)
                    T = np.zeros((n, n), dtype=int)
                    
                    for _, row in df_vs.iterrows():
                        i = idx.get(row["íŒ€ëª…"])
                        if i is None:
                            continue
                        for opp in teams:
                            if opp not in df_vs.columns or i == idx[opp]:
                                continue
                            w, l, t = parse_wlt(row[opp])
                            if not np.isnan(w):
                                j = idx[opp]
                                W[i, j], L[i, j], T[i, j] = int(w), int(l), int(t)
                    
                    # ëŒ€ì¹­ ë³´ì •
                    for i in range(n):
                        for j in range(n):
                            if i == j:
                                continue
                            W[j, i], L[j, i], T[j, i] = L[i, j], W[i, j], T[i, j]
                    
                    G_played = W + L + T
                    
                    # 3) Bradley-Terry ëª¨í˜• ì¶”ì •
                    def bt_fit(W, T, G, max_iter=1000, tol=1e-10):
                        n = W.shape[0]
                        s = np.ones(n)
                        s /= s.sum()
                        
                        def update(s):
                            new_s = np.zeros_like(s, dtype=float)
                            for i in range(n):
                                w_i = (W[i, :] + 0.5 * T[i, :]).sum()
                                denom = 0.0
                                for j in range(n):
                                    if i == j:
                                        continue
                                    n_ij = G[i, j]
                                    if n_ij > 0:
                                        denom += n_ij / (s[i] + s[j])
                                new_s[i] = w_i / denom if denom > 0 else s[i]
                            new_s = np.clip(new_s, 1e-12, None)
                            return new_s / new_s.sum()
                        
                        for _ in range(max_iter):
                            new_s = update(s)
                            if np.max(np.abs(new_s - s)) < tol:
                                return new_s
                            s = new_s
                        return s
                    
                    s = bt_fit(W, T, G_played)
                    S = s.reshape(-1, 1)
                    
                    # í™•ë¥  ê³„ì‚° ì‹œ ì•ˆì „ì¥ì¹˜ ì¶”ê°€
                    with np.errstate(divide='ignore', invalid='ignore'):
                        P = S / (S + S.T)
                        # NaN, ë¬´í•œëŒ€, ìŒìˆ˜ ê°’ ì²˜ë¦¬
                        P = np.nan_to_num(P, nan=0.5, posinf=1.0, neginf=0.0)
                        P = np.clip(P, 0.0, 1.0)
                    np.fill_diagonal(P, 0.0)
                    
                    # ë¬´ìŠ¹ë¶€ìœ¨ ê³„ì‚°
                    with np.errstate(divide='ignore', invalid='ignore'):
                        tie_pair = np.where(G_played > 0, T / G_played, np.nan)
                    league_tie_rate = float(np.nanmean(tie_pair))
                    tie_pair = np.where(np.isnan(tie_pair), league_tie_rate, tie_pair)
                    # ë¬´ìŠ¹ë¶€ìœ¨ë„ ì•ˆì „ì¥ì¹˜ ì¶”ê°€
                    tie_pair = np.nan_to_num(tie_pair, nan=0.0, posinf=1.0, neginf=0.0)
                    tie_pair = np.clip(tie_pair, 0.0, 1.0)
                    np.fill_diagonal(tie_pair, 0.0)
                    
                    # 4) ì‹œë®¬ë ˆì´ì…˜
                    TARGET_PER_PAIR = 16
                    R = np.maximum(0, TARGET_PER_PAIR - G_played)
                    np.fill_diagonal(R, 0)
                    
                    SEASONS = 1_000_000
                    rng = np.random.default_rng(42)
                    
                    cur_w = df_final.set_index("íŒ€ëª…").loc[teams, "ìŠ¹"].to_numpy()
                    cur_l = df_final.set_index("íŒ€ëª…").loc[teams, "íŒ¨"].to_numpy()
                    cur_t = df_final.set_index("íŒ€ëª…").loc[teams, "ë¬´"].to_numpy()
                    
                    final_w = np.zeros((SEASONS, n), dtype=np.int32)
                    final_l = np.zeros((SEASONS, n), dtype=np.int32)
                    final_t = np.zeros((SEASONS, n), dtype=np.int32)
                    
                    pairs = [(i, j) for i in range(n) for j in range(i + 1, n) if R[i, j] > 0]
                    for (i, j) in pairs:
                        r = int(R[i, j])
                        # í™•ë¥ ê°’ ì•ˆì „ì¥ì¹˜
                        tie_prob = np.clip(float(tie_pair[i, j]), 0.0, 1.0)
                        win_prob = np.clip(float(P[i, j]), 0.0, 1.0)
                        
                        ties = rng.binomial(r, tie_prob, size=SEASONS)
                        non_ties = r - ties
                        wins_i = rng.binomial(non_ties, win_prob, size=SEASONS)
                        wins_j = non_ties - wins_i
                        
                        final_w[:, i] += wins_i
                        final_l[:, i] += wins_j
                        final_t[:, i] += ties
                        final_w[:, j] += wins_j
                        final_l[:, j] += wins_i
                        final_t[:, j] += ties
                    
                    # í˜„ì¬ ì„±ì  í•©ì‚°
                    final_w += cur_w
                    final_l += cur_l
                    final_t += cur_t
                    
                    # ìµœì¢… ìŠ¹ë¥ 
                    games_tot = final_w + final_l + final_t
                    with np.errstate(divide='ignore', invalid='ignore'):
                        win_pct = (final_w + 0.5 * final_t) / np.maximum(1, games_tot)
                        # ìŠ¹ë¥ ë„ ì•ˆì „ì¥ì¹˜ ì¶”ê°€
                        win_pct = np.nan_to_num(win_pct, nan=0.0, posinf=1.0, neginf=0.0)
                        win_pct = np.clip(win_pct, 0.0, 1.0)
                    
                    # ìˆœìœ„ ì‚°ì •
                    noise = rng.normal(0, 1e-9, size=win_pct.shape)
                    rank_order = np.argsort(-(win_pct + noise), axis=1)
                    seed = np.empty_like(rank_order)
                    for s_idx in range(SEASONS):
                        seed[s_idx, rank_order[s_idx]] = np.arange(1, n + 1)
                    
                    # 5) ìˆœìœ„ ë¶„í¬ ê³„ì‚°
                    rank_pct = np.zeros((n, n), dtype=float)
                    for i in range(n):
                        counts = np.bincount(seed[:, i], minlength=n + 1)[1:]
                        rank_pct[i] = (counts / SEASONS) * 100.0
                    
                    rank_cols = [f"{r}ìœ„" for r in range(1, n + 1)]
                    rank_df = pd.DataFrame(rank_pct, columns=rank_cols, index=teams).round(1)
                    
                    # ìŠ¹íŒ¨ë¬´ í–‰ë ¬ì„ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
                    def create_vs_table(W, L, T, teams):
                        vs_data = []
                        for i, team1 in enumerate(teams):
                            row = [team1]
                            for j, team2 in enumerate(teams):
                                if i == j:
                                    row.append("-")
                                else:
                                    w, l, t = W[i, j], L[i, j], T[i, j]
                                    if w == 0 and l == 0 and t == 0:
                                        row.append("-")
                                    else:
                                        row.append(f"{w}-{l}-{t}")
                            vs_data.append(row)
                        
                        vs_cols = ["íŒ€ëª…"] + teams
                        return pd.DataFrame(vs_data, columns=vs_cols)
                    
                    # 7) íˆíŠ¸ë§µ ì‹œê°í™” (í˜„ì¬ ìˆœìœ„ ìˆœì„œë¡œ ì •ë ¬)
                    fig_heatmap = go.Figure()
                    
                    # í˜„ì¬ ìˆœìœ„ ìˆœì„œë¡œ íŒ€ ì •ë ¬ (1ìœ„ë¶€í„° 10ìœ„ê¹Œì§€)
                    current_rank_order = df_final.sort_values('ìˆœìœ„')['íŒ€ëª…'].tolist()
                    # rank_pct í–‰ë ¬ì„ í˜„ì¬ ìˆœìœ„ ìˆœì„œë¡œ ì¬ì •ë ¬
                    rank_pct_sorted = rank_pct[[teams.index(team) for team in current_rank_order]]
                    teams_sorted = current_rank_order
                    
                    # í°ìƒ‰â†’ë¹¨ê°• ìƒ‰ìƒë§µ
                    colorscale = [[0, 'white'], [1, 'red']]
                    
                    fig_heatmap.add_trace(go.Heatmap(
                        z=rank_pct_sorted,
                        x=rank_cols,
                        y=teams_sorted,
                        colorscale=colorscale,
                        zmin=0,
                        zmax=100,
                        text=rank_pct_sorted.round(1),
                        texttemplate="%{text:.2f}",
                        textfont={"size": 10},
                        showscale=True,
                        colorbar=dict(title=dict(text="í™•ë¥  (%)", side="right")),
                        showlegend=False
                    ))
                    
                    fig_heatmap.update_layout(
                        title="Bradley-Terry ëª¨í˜• ê¸°ë°˜ íŒ€ë³„ ìµœì¢… ìˆœìœ„ ì˜ˆì¸¡ (10ë§Œ íšŒ ì‹œë®¬ë ˆì´ì…˜)",
                        xaxis_title="ìµœì¢… ìˆœìœ„",
                        yaxis_title="íŒ€ëª… (í˜„ì¬ ìˆœìœ„ ìˆœ)",
                        width=800,
                        height=500,
                        showlegend=False
                    )
                    
                    fig_heatmap.update_xaxes(showgrid=False)
                    fig_heatmap.update_yaxes(showgrid=False)
                    
                    st.plotly_chart(fig_heatmap, use_container_width=True)                    
                    st.success("Bradley-Terry ëª¨í˜• ìˆœìœ„ ì˜ˆì¸¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                        # ê²°ê³¼ í…Œì´ë¸” í‘œì‹œ (í˜„ì¬ ìˆœìœ„ ìˆœì„œë¡œ ì •ë ¬)
                    # 6) íŒ€ê°„ ìŠ¹íŒ¨í‘œ í‘œì‹œ
                    #   st.subheader("ğŸ“Š íŒ€ê°„ ìŠ¹íŒ¨í‘œ (Bradley-Terry ëª¨í˜• ì…ë ¥ ë°ì´í„°)")
                    with st.expander("ğŸ” íŒ€ê°„ ìŠ¹íŒ¨í‘œ (Bradley-Terry ëª¨í˜• ì…ë ¥ ë°ì´í„°)", expanded=False):                  
                        vs_table = create_vs_table(W, L, T, teams)
                        safe_dataframe_display(vs_table, use_container_width=True, hide_index=True)

                    with st.expander("ğŸ” ìˆœìœ„ë³„ í™•ë¥  ë¶„í¬ (%)", expanded=False):
                        # st.subheader("ğŸ“Š ìˆœìœ„ë³„ í™•ë¥  ë¶„í¬ (%)")
                        rank_df_sorted = rank_df.loc[current_rank_order].reset_index().rename(columns={"index": "íŒ€ëª…"})
                        safe_dataframe_display(rank_df_sorted, use_container_width=True, hide_index=True)

                    
                except Exception as e:
                    st.error(f"Bradley-Terry ëª¨í˜• ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("íŒ€ê°„ ìŠ¹íŒ¨í‘œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    
                    # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
                    with st.expander("ğŸ” ë””ë²„ê·¸ ì •ë³´", expanded=False):
                        try:
                            st.write("íŒ€ê°„ ìŠ¹íŒ¨í‘œ ì›ë³¸ ë°ì´í„°:")
                            st.write(df_vs_raw.head())
                            st.write("ì •ê·œí™”ëœ íŒ€ê°„ ìŠ¹íŒ¨í‘œ:")
                            st.write(df_vs.head())
                            st.write("ìŠ¹íŒ¨ë¬´ í–‰ë ¬ ì •ë³´:")
                            st.write(f"W í–‰ë ¬ í˜•íƒœ: {W.shape}")
                            st.write(f"L í–‰ë ¬ í˜•íƒœ: {L.shape}")
                            st.write(f"T í–‰ë ¬ í˜•íƒœ: {T.shape}")
                            st.write(f"G_played í–‰ë ¬ í˜•íƒœ: {G_played.shape}")
                        except Exception as debug_e:
                            st.write(f"ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {debug_e}")

    with tab5:
        # st.header("ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥")
        try:
            ws = _open_log_worksheet("SimulationLog")
            if ws is None:
                return
            # ë§ì€ í–‰ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ get_all_records ëŒ€ì‹  get_all_values í›„ DataFrame ë³€í™˜
            values = ws.get_all_values()
            if not values or len(values) < 2:
                st.info("ì•„ì§ ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            header, rows = values[0], values[1:]
            df_hist = pd.DataFrame(rows, columns=header)
            # ìŠ¤í‚¤ë§ˆ ì •ê·œí™”
            rename_map = {
                'ìš°ìŠ¹': 'ìš°ìŠ¹',
                'PO': 'PO',
                'íŒ€ëª…': 'íŒ€ëª…',
                'timestamp': 'timestamp',
                'base_date': 'base_date',
            }
            for k, v in list(rename_map.items()):
                if k not in df_hist.columns and v in df_hist.columns:
                    # ì´ë¯¸ ì›í•˜ëŠ” ì´ë¦„ì´ë©´ ìŠ¤í‚µ
                    continue
                if k in df_hist.columns:
                    df_hist.rename(columns={k: v}, inplace=True)
            # íƒ€ì… ìºìŠ¤íŒ…
            if 'timestamp' in df_hist.columns:
                try:
                    df_hist['timestamp'] = pd.to_datetime(df_hist['timestamp'], errors='coerce')
                except Exception:
                    pass
            if 'base_date' in df_hist.columns:
                try:
                    df_hist['base_date'] = pd.to_datetime(df_hist['base_date'], errors='coerce').dt.date
                except Exception:
                    pass
            for col in ['ìš°ìŠ¹', 'PO']:
                if col in df_hist.columns:
                    df_hist[col] = pd.to_numeric(df_hist[col], errors='coerce')
            if df_hist.empty:
                st.info("ì•„ì§ ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            # ì¼ì ì»¬ëŸ¼ ìƒì„±
            # ë‚ ì§œ ì†ŒìŠ¤ ì„ íƒ: ê¸°ë³¸ì€ ê¸°ì¤€ì¼ì(base_date), í•„ìš” ì‹œ ì‹¤í–‰ì¼(timestamp) ê¸°ì¤€ìœ¼ë¡œ ì „í™˜ ê°€ëŠ¥
            src_col1, src_col2 = st.columns(2)
            # with src_col1:
            #     use_run_date = st.checkbox("ì‹¤í–‰ì¼(ë¡œê·¸ ì‹œê°) ê¸°ì¤€ìœ¼ë¡œ ë³´ê¸°", value=False)
            # ê¸°ì¤€ì¼ì ìš°ì„  ë˜ëŠ” ì‹¤í–‰ì¼ ì„ íƒ
            use_run_date = False
            if use_run_date and 'timestamp' in df_hist.columns:
                df_hist['date'] = pd.to_datetime(df_hist['timestamp'], errors='coerce').dt.date
            elif 'base_date' in df_hist.columns and df_hist['base_date'].notna().any():
                df_hist['date'] = df_hist['base_date']
            elif 'timestamp' in df_hist.columns:
                df_hist['date'] = pd.to_datetime(df_hist['timestamp'], errors='coerce').dt.date
            else:
                df_hist['date'] = pd.NaT
            # n_days = st.number_input("ìµœê·¼ Nì¼", min_value=3, max_value=180, value=30, step=1)
            show_markers = True #st.checkbox("ë§ˆì»¤ í‘œì‹œ", value=True)

            # ì¼ìë³„ ì§‘ê³„: ë™ì¼ ì¼ìì— ì—¬ëŸ¬ ë¡œê·¸ê°€ ìˆìœ¼ë©´ í‰ê· ìœ¼ë¡œ ì§‘ê³„(íŒ€ë³„)
            df_day = df_hist.groupby(['date','íŒ€ëª…'], as_index=False).agg({'ìš°ìŠ¹':'mean','PO':'mean'})
            df_day = df_day.sort_values(['date','íŒ€ëª…'])
            # ìµœê·¼ Nì¼ í•„í„°
            # try:
            #     if df_day['date'].notna().any():
            #         last_date = pd.to_datetime(df_day['date']).max()
            #         start_date = (pd.to_datetime(last_date) - pd.Timedelta(days=int(n_days)-1)).date()
            #         mask = pd.to_datetime(df_day['date']).dt.date >= start_date
            #         df_day = df_day.loc[mask]
            # except Exception:
            #     pass

            # ë²”ë¡€(íŒ€ëª…) ì •ë ¬: í˜„ì¬ ìˆœìœ„ ìŠ¹ë¥  ë†’ì€ ìˆœ
            try:
                team_order = df_standings.sort_values('ìŠ¹ë¥ ', ascending=False)['íŒ€ëª…'].tolist() if 'ìŠ¹ë¥ ' in df_standings.columns else df_standings['íŒ€ëª…'].tolist()
            except Exception:
                team_order = None

            # íŒ€ë³„ ë¼ì¸í”Œë(ìš°ìŠ¹) â€” ì¼ìë³„ í‰ê· 
            if {'date','íŒ€ëª…','ìš°ìŠ¹'}.issubset(df_day.columns):
                fig_c = px.line(
                    df_day, x='date', y='ìš°ìŠ¹', color='íŒ€ëª…', markers=show_markers,
                    title='íŒ€ë³„ ìš°ìŠ¹ í™•ë¥  (ì¼ìë³„)',
                    category_orders={'íŒ€ëª…': team_order} if team_order else None
                )
                try:
                    # ë¼ì¸ ìƒ‰ìƒ ê³ ì •
                    for tr in fig_c.data:
                        team = tr.name
                        if team in TEAM_COLOR_MAP:
                            tr.line.color = TEAM_COLOR_MAP[team]
                            tr.marker.color = TEAM_COLOR_MAP[team]
                except Exception:
                    pass
                # ë§ˆì»¤ ì‚¬ì´ì¦ˆ í‚¤ìš°ê¸°
                try:
                    fig_c.update_traces(marker=dict(size=10))
                except Exception:
                    pass
                fig_c.update_yaxes(range=[0, 100], dtick=10, ticksuffix='%')
                st.plotly_chart(fig_c, use_container_width=True)
                # ê·¸ë˜í”„ ë°”ë¡œ ì•„ë˜ì— í•´ë‹¹ ë°ì´í„°(í”¼ë²—) í‘œì‹œ
                try:
                    pivot_win = (
                        df_day.pivot_table(index='date', columns='íŒ€ëª…', values='ìš°ìŠ¹', aggfunc='mean').sort_index()
                    )
                    if team_order:
                        existing_cols = [c for c in team_order if c in pivot_win.columns]
                        pivot_win = pivot_win.reindex(columns=existing_cols)
                    pivot_win = pivot_win.dropna(how='all')
                    with st.expander("ğŸ” ì¼ìë³„ ìš°ìŠ¹ í™•ë¥ ", expanded=False):
                        safe_dataframe_display(pivot_win.round(2).reset_index(), use_container_width=True, hide_index=True)
                except Exception:
                    pass
            # íŒ€ë³„ ë¼ì¸í”Œë(PO) â€” ì¼ìë³„ í‰ê· 
            if {'date','íŒ€ëª…','PO'}.issubset(df_day.columns):
                fig_p = px.line(
                    df_day, x='date', y='PO', color='íŒ€ëª…', markers=show_markers,
                    title='íŒ€ë³„ PO ì§„ì¶œ í™•ë¥  (ì¼ìë³„)',
                    category_orders={'íŒ€ëª…': team_order} if team_order else None
                )
                try:
                    for tr in fig_p.data:
                        team = tr.name
                        if team in TEAM_COLOR_MAP:
                            tr.line.color = TEAM_COLOR_MAP[team]
                            tr.marker.color = TEAM_COLOR_MAP[team]
                except Exception:
                    pass
                # ë§ˆì»¤ ì‚¬ì´ì¦ˆ í‚¤ìš°ê¸°
                try:
                    fig_p.update_traces(marker=dict(size=10))
                except Exception:
                    pass
                fig_p.update_yaxes(range=[0, 100], dtick=10, ticksuffix='%')
                st.plotly_chart(fig_p, use_container_width=True)
                try:
                    pivot_po = (
                        df_day.pivot_table(index='date', columns='íŒ€ëª…', values='PO', aggfunc='mean').sort_index()
                    )
                    if team_order:
                        existing_cols_po = [c for c in team_order if c in pivot_po.columns]
                        pivot_po = pivot_po.reindex(columns=existing_cols_po)
                    pivot_po = pivot_po.dropna(how='all')
                    with st.expander("ğŸ” ì¼ìë³„ PO í™•ë¥ ", expanded=False):
                        safe_dataframe_display(pivot_po.round(2).reset_index(), use_container_width=True, hide_index=True)
                except Exception:
                    pass

            # í‘œëŠ” ì•„ë˜ë¡œ ì´ë™í•˜ì—¬ ì›ë³¸ ê¸°ë¡ì„ ê·¸ëŒ€ë¡œ í‘œì‹œ
            df_hist_sorted = df_hist.sort_values('timestamp') if 'timestamp' in df_hist else df_hist

            with st.expander("ğŸ” ì›ë³¸ ë°ì´í„°", expanded=False):
                st.dataframe(df_hist_sorted.drop(columns=['timestamp','date']).sort_values(['base_date', 'íŒ€ëª…'], ascending=False), use_container_width=True,
                            hide_index=True)
        except Exception as e:
            st.info("ì´ë ¥ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. " + str(e))

if __name__ == "__main__":
    main()