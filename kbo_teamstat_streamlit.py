import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import random
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime 
import gspread
from gspread.exceptions import APIError as GspreadAPIError
from google.oauth2.service_account import Credentials

def _diagnose_gsheet_setup() -> str:
    """Google Sheets ì—°ë™ í™˜ê²½ ì§„ë‹¨ ìš”ì•½ ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    messages = []
    try:
        if "gcp_service_account" not in st.secrets:
            messages.append("- secretsì— [gcp_service_account] ì„¹ì…˜ì´ ì—†ìŒ (.streamlit/secrets.toml í™•ì¸)")
            return "\n".join(messages)

        gcp = dict(st.secrets["gcp_service_account"])  # ë³µì‚¬ë³¸
        required = [
            "type",
            "project_id",
            "private_key_id",
            "private_key",
            "client_email",
            "client_id",
            "token_uri",
        ]
        missing = [k for k in required if k not in gcp or not gcp[k]]
        if missing:
            messages.append(f"- ëˆ„ë½ëœ í‚¤: {', '.join(missing)}")

        pk = str(gcp.get("private_key", ""))
        if not pk.startswith("-----BEGIN PRIVATE KEY-----"):
            messages.append("- private_key í˜•ì‹ ì˜¤ë¥˜: PEM í—¤ë”ê°€ ì—†ìŒ")
        if "\\n" not in gcp.get("private_key", "") and "\n" not in pk:
            messages.append("- private_key ì¤„ë°”ê¿ˆ ëˆ„ë½ ê°€ëŠ¥ì„±: ë¡œì»¬ TOMLì—ì„œëŠ” \\n ë¡œ ì´ìŠ¤ì¼€ì´í”„ í•„ìš”")

        email = str(gcp.get("client_email", ""))
        if not email.endswith("iam.gserviceaccount.com"):
            messages.append("- client_email ê°’ì´ ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹˜")

        if not messages:
            messages.append("- secrets í˜•ì‹ì€ ì •ìƒìœ¼ë¡œ ë³´ì„. Sheets/Drive API í™œì„±í™” ë° ì‹œíŠ¸ ê³µìœ  ê¶Œí•œ í™•ì¸ í•„ìš”")
    except Exception as e:
        messages.append(f"- ì§„ë‹¨ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    return "\n".join(messages)

def _format_gspread_error(err: Exception) -> str:
    """gspread ì˜ˆì™¸ë¥¼ ì½ê¸° ì‰¬ìš´ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        # gspread APIErrorì¸ ê²½ìš° ìƒì„¸ íŒŒì‹±
        if isinstance(err, GspreadAPIError):
            status_code = None
            reason = None
            message = None

            try:
                resp = getattr(err, "response", None)
                if resp is not None:
                    status_code = getattr(resp, "status_code", None)
                    # JSON ë³¸ë¬¸ íŒŒì‹± ì‹œë„
                    try:
                        data = resp.json()
                        err_obj = data.get("error", {}) if isinstance(data, dict) else {}
                        message = err_obj.get("message")
                        # Google API í‘œì¤€ ì—ëŸ¬ êµ¬ì¡°ì—ì„œ reason ì¶”ì¶œ
                        details = err_obj.get("errors") or []
                        if isinstance(details, list) and details:
                            reason = details[0].get("reason")
                    except Exception:
                        message = getattr(resp, "text", None)
            except Exception:
                pass

            parts = []
            if status_code is not None:
                parts.append(f"status={status_code}")
            if reason:
                parts.append(f"reason={reason}")
            if message:
                parts.append(f"message={message}")
            if not parts:
                parts.append(str(err))
            return "; ".join(parts)

        # ì¼ë°˜ ì˜ˆì™¸ëŠ” ë¬¸ìì—´í™”
        return str(err)
    except Exception:
        return str(err)

def get_gsheet_client():
    try:
        scope = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive",
        ]

        # secrets ì¡´ì¬ í™•ì¸
        if "gcp_service_account" not in st.secrets:
            st.error("Streamlit secretsì— 'gcp_service_account' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. .streamlit/secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.")
            return None

        gcp_dict = dict(st.secrets["gcp_service_account"])  # ë³µì‚¬ë³¸ ì‚¬ìš©

        # í•„ìˆ˜ í‚¤ ì¡´ì¬ í™•ì¸
        required_keys = [
            "type",
            "project_id",
            "private_key_id",
            "private_key",
            "client_email",
            "client_id",
            "token_uri",
        ]
        missing = [k for k in required_keys if k not in gcp_dict or not gcp_dict[k]]
        if missing:
            st.error(f"gcp_service_account ëˆ„ë½ í‚¤: {', '.join(missing)}")
            return None

        # private_key ê°œí–‰ ë° í˜•ì‹ ì •ë¦¬
        private_key = gcp_dict.get('private_key', '')
        if isinstance(private_key, str):
            private_key = private_key.replace('\\n', '\n').replace('\\r\\n', '\n').replace('\\r', '\n')
        if not str(private_key).startswith('-----BEGIN PRIVATE KEY-----'):
            st.error("gcp_service_account.private_key í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. PEM í—¤ë”ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
            return None
        gcp_dict['private_key'] = private_key

        try:
            credentials = Credentials.from_service_account_info(gcp_dict, scopes=scope)
        except Exception as cred_err:
            st.error(f"ì„œë¹„ìŠ¤ ê³„ì • ìê²© ì¦ëª… ìƒì„± ì‹¤íŒ¨: {cred_err}")
            return None

        try:
            client = gspread.authorize(credentials)
            return client
        except Exception as auth_err:
            st.error(f"gspread ì¸ì¦ ì‹¤íŒ¨: {auth_err}")
            return None
    except Exception as e:
        st.error(f"Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        return None

def safe_dataframe_display(df, use_container_width=True, hide_index=True):
    """ë°ì´í„°í”„ë ˆì„ì„ ì•ˆì „í•˜ê²Œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ëª¨ë“  ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ Arrow í˜¸í™˜ì„± ë¬¸ì œ ë°©ì§€
        df_display = df.copy()
        for col in df_display.columns:
            try:
                df_display[col] = df_display[col].astype(str)
            except:
                # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê°’ ìœ ì§€
                pass
        
        st.dataframe(df_display, use_container_width=use_container_width, hide_index=hide_index)
    except Exception as e:
        st.error(f"ë°ì´í„°í”„ë ˆì„ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
        st.write("ë°ì´í„° í‘œì‹œì— ë¬¸ì œê°€ ìˆì–´ ì›ë³¸ í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤:")
        st.write(df)

def clean_dataframe_for_display(df):
    """ë°ì´í„°í”„ë ˆì„ì„ í‘œì‹œìš©ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        df_clean = df.copy()
        
        # IP ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
        if 'IP' in df_clean.columns:
            df_clean['IP'] = df_clean['IP'].astype(str)
        
        # ìˆ«ì ì»¬ëŸ¼ì€ ì†Œìˆ˜ì  3ìë¦¬ê¹Œì§€ í‘œì‹œ
        for col in df_clean.columns:
            if col not in ['íŒ€ëª…', 'ìˆœìœ„']:  # íŒ€ëª…ê³¼ ìˆœìœ„ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                try:
                    df_clean[col] = df_clean[col].astype(float).round(3)
                except:
                    pass

        # ëª¨ë“  ìˆ«ì ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ Arrow í˜¸í™˜ì„± ë¬¸ì œ ë°©ì§€
        for col in df_clean.columns:
            if col not in ['íŒ€ëª…', 'ìˆœìœ„']:  # íŒ€ëª…ê³¼ ìˆœìœ„ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                try:
                    df_clean[col] = df_clean[col].astype(str)
                except:
                    pass
        
        return df_clean
    except Exception as e:
        st.error(f"ë°ì´í„°í”„ë ˆì„ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return df


def append_simulation_to_sheet(df_result, sheet_name="SimulationLog"):
    try:
        client = get_gsheet_client()
        if client is None:
            diag = _diagnose_gsheet_setup()
            st.error("êµ¬ê¸€ ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì›ì¸ ì§„ë‹¨:\n" + diag)
            return
            
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸° (secretsì—ì„œ ID/URL ìš°ì„ )
        sh = None
        try:
            cfg = st.secrets.get("gsheet", {})
        except Exception:
            cfg = {}

        spreadsheet_id = None
        if isinstance(cfg, dict):
            spreadsheet_id = cfg.get("spreadsheet_id")
            spreadsheet_url = cfg.get("spreadsheet_url")
            if not spreadsheet_id and spreadsheet_url:
                try:
                    import re as _re
                    m = _re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", str(spreadsheet_url))
                    if m:
                        spreadsheet_id = m.group(1)
                except Exception:
                    pass

        if spreadsheet_id:
            try:
                sh = client.open_by_key(spreadsheet_id)
            except Exception as e:
                st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸(ID) ì—´ê¸° ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                return
        else:
            # ID ë¯¸ì§€ì • ì‹œ ì œëª©ìœ¼ë¡œ ì—´ê¸° ì‹œë„, ì‹¤íŒ¨í•˜ë©´ ìƒì„±
            try:
                sh = client.open("KBO_Simulation_Log")
            except Exception as open_err:
                try:
                    sh = client.create("KBO_Simulation_Log")
                except Exception as create_err:
                    err_text = str(create_err)
                    if "quota" in err_text.lower() and "storage" in err_text.lower():
                        st.error(
                            "Google Drive ì €ì¥ ìš©ëŸ‰ ì´ˆê³¼ë¡œ ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                            "í•´ê²° ë°©ë²•:\n"
                            "- ë“œë¼ì´ë¸Œ ìš©ëŸ‰ í™•ë³´(íœ´ì§€í†µ ë¹„ìš°ê¸° í¬í•¨) í›„ ë‹¤ì‹œ ì‹œë„\n"
                            "- ë˜ëŠ” ê¸°ì¡´ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì˜ IDë¥¼ secrets.gsheet.spreadsheet_idì— ì„¤ì •í•˜ê³ , ì„œë¹„ìŠ¤ ê³„ì •ì„ í¸ì§‘ìë¡œ ê³µìœ "
                        )
                    else:
                        st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨:\n" + _format_gspread_error(create_err))
                    return

        # ì›Œí¬ì‹œíŠ¸ ì—´ê¸° (ì—†ìœ¼ë©´ ìƒì„±) ë° í—¤ë” ì¶”ê°€
        created_new_worksheet = False
        try:
            worksheet = sh.worksheet(sheet_name)
        except Exception as ws_open_err:
            try:
                worksheet = sh.add_worksheet(title=sheet_name, rows="1000", cols="20")
                created_new_worksheet = True
            except Exception as ws_create_err:
                st.error("ì›Œí¬ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨:\n" + _format_gspread_error(ws_create_err))
                return

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        df_result = df_result.copy()
        df_result.insert(0, "timestamp", timestamp)

        # ìƒˆ ì›Œí¬ì‹œíŠ¸ì¸ ê²½ìš° í—¤ë” ì¶”ê°€
        if created_new_worksheet:
            try:
                worksheet.append_row(df_result.columns.tolist(), value_input_option="USER_ENTERED")
            except Exception as header_err:
                st.warning("í—¤ë” ì¶”ê°€ ì‹¤íŒ¨(ê³„ì† ì§„í–‰):\n" + _format_gspread_error(header_err))

        try:
            worksheet.append_rows(df_result.values.tolist(), value_input_option="USER_ENTERED")
        except Exception as append_err:
            st.error("ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨:\n" + _format_gspread_error(append_err))
            return
        st.success(f"ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ '{sheet_name}' ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error("Google Sheets ì €ì¥ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜:\n" + _format_gspread_error(e))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="KBO íŒ€ í†µê³„ ë¶„ì„ê¸°",
    page_icon="âš¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .team-stats {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data(ttl=3600)  # 1ì‹œê°„ë§ˆë‹¤ ìºì‹œ ê°±ì‹ 
def scrape_kbo_team_batting_stats():
    """KBO íŒ€ë³„ íƒ€ì ê¸°ë¡ ìŠ¤í¬ë˜í•‘"""
    url = "https://www.koreabaseball.com/Record/Team/Hitter/Basic1.aspx"
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        table = soup.find('table', class_='tEx') or soup.find('table')
        
        if table is None:
            st.error("íƒ€ì ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        rows = table.find_all('tr')
        data = []
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            row_text = [cell.get_text().strip() for cell in cells]
            
            for j, text in enumerate(row_text):
                if text in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                    if len(row_text) >= 15:
                        team_data = []
                        team_data.append(text)
                        
                        for k in range(j+1, min(j+14, len(row_text))):
                            try:
                                val = row_text[k]
                                if '.' in val and val.replace('.', '').replace('-', '').isdigit():
                                    team_data.append(float(val))
                                elif val.replace('-', '').isdigit():
                                    team_data.append(int(val))
                                else:
                                    team_data.append(val)
                            except:
                                team_data.append(row_text[k])
                        
                        if len(team_data) == 14:
                            data.append(team_data)
                    break
        
        if not data:
            st.error("íŒ€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        columns = ['íŒ€ëª…', 'AVG', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'TB', 'RBI', 'SAC', 'SF']
        df = pd.DataFrame(data, columns=columns)
        df = df.sort_values('AVG', ascending=False).reset_index(drop=True)
        df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
        
        return df
        
    except Exception as e:
        st.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

@st.cache_data(ttl=3600)
def scrape_kbo_team_batting_stats_advanced():
    """KBO íŒ€ë³„ íƒ€ì ê³ ê¸‰ ê¸°ë¡ ìŠ¤í¬ë˜í•‘ (ì¶œë£¨ìœ¨, ì¥íƒ€ìœ¨, OPS ë“±)"""
    url = "https://www.koreabaseball.com/Record/Team/Hitter/Basic2.aspx"
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        table = soup.find('table', class_='tEx') or soup.find('table')
        
        if table is None:
            st.error("ê³ ê¸‰ íƒ€ì ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        rows = table.find_all('tr')
        data = []
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            row_text = [cell.get_text().strip() for cell in cells]
            
            # íŒ€ëª…ì´ í¬í•¨ëœ í–‰ì¸ì§€ í™•ì¸
            team_found = False
            for text in row_text:
                if text in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                    team_found = True
                    break
            
            if team_found and len(row_text) >= 12:  # íŒ€ëª… + ìµœì†Œ 11ê°œ ì§€í‘œ
                team_data = []
                # íŒ€ëª… ì°¾ê¸°
                for text in row_text:
                    if text in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                        team_data.append(text)
                        break
                
                # ë‚˜ë¨¸ì§€ ë°ì´í„° ì¶”ì¶œ (AVG, BB, IBB, HBP, SO, GDP, SLG, OBP, OPS, MH, RISP)
                data_started = False
                for val in row_text:
                    if data_started and len(team_data) < 12:  # íŒ€ëª… + 11ê°œ ì§€í‘œ
                        try:
                            if '.' in val and val.replace('.', '').replace('-', '').isdigit():
                                team_data.append(float(val))
                            elif val.replace('-', '').isdigit():
                                team_data.append(int(val))
                            else:
                                team_data.append(val)
                        except:
                            team_data.append(val)
                    elif val in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                        data_started = True
                
                if len(team_data) == 12:  # íŒ€ëª… + 11ê°œ ì§€í‘œ
                    data.append(team_data)
        
        if not data:
            st.error("íŒ€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        columns = ['íŒ€ëª…', 'AVG', 'BB', 'IBB', 'HBP', 'SO', 'GDP', 'SLG', 'OBP', 'OPS', 'MH', 'RISP']
        df = pd.DataFrame(data, columns=columns)
        df = df.sort_values('AVG', ascending=False).reset_index(drop=True)
        df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
        
        return df
        
    except Exception as e:
        st.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

@st.cache_data(ttl=3600)
def scrape_kbo_team_pitching_stats():
    """KBO íŒ€ë³„ íˆ¬ìˆ˜ ê¸°ë¡ ìŠ¤í¬ë˜í•‘"""
    url = "https://www.koreabaseball.com/Record/Team/Pitcher/Basic1.aspx"
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        table = soup.find('table', class_='tEx') or soup.find('table')
        
        if table is None:
            st.error("íˆ¬ìˆ˜ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        rows = table.find_all('tr')
        data = []
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            row_text = [cell.get_text().strip() for cell in cells]
            
            for j, text in enumerate(row_text):
                if text in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                    if len(row_text) >= 18:
                        team_data = []
                        team_data.append(text)
                        
                        for k in range(j+1, min(j+17, len(row_text))):
                            try:
                                val = row_text[k]
                                if k == j+9:  # IP ì»¬ëŸ¼
                                    try:
                                        if '/' in val:
                                            parts = val.split()
                                            if len(parts) == 2:
                                                whole = float(parts[0])
                                                frac_parts = parts[1].split('/')
                                                fraction = float(frac_parts[0]) / float(frac_parts[1])
                                                team_data.append(str(whole + fraction))  # ë¬¸ìì—´ë¡œ ë³€í™˜
                                            else:
                                                team_data.append(str(float(val)) if val.replace('.', '').replace('-', '').isdigit() else val)
                                        else:
                                            team_data.append(str(float(val)) if val.replace('.', '').replace('-', '').isdigit() else val)
                                    except:
                                        team_data.append(str(val))  # ë¬¸ìì—´ë¡œ ë³€í™˜
                                elif '.' in val and val.replace('.', '').replace('-', '').isdigit():
                                    team_data.append(float(val))
                                elif val.replace('-', '').isdigit():
                                    team_data.append(int(val))
                                else:
                                    team_data.append(val)
                            except:
                                team_data.append(row_text[k])
                        
                        if len(team_data) == 17:
                            data.append(team_data)
                    break
        
        if not data:
            st.error("íŒ€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        columns = ['íŒ€ëª…', 'ERA', 'G', 'W', 'L', 'SV', 'HLD', 'WPCT', 'IP', 'H', 'HR', 'BB', 'HBP', 'SO', 'R', 'ER', 'WHIP']
        df = pd.DataFrame(data, columns=columns)
        
        # IP ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ í™•ì‹¤íˆ ë³€í™˜
        try:
            df['IP'] = df['IP'].astype(str)
        except:
            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            df['IP'] = df['IP'].apply(lambda x: str(x) if x is not None else '')
        
        df = df.sort_values('ERA', ascending=True).reset_index(drop=True)
        df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
        
        return df
        
    except Exception as e:
        st.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

@st.cache_data(ttl=3600)
def scrape_kbo_team_pitching_stats_advanced():
    """KBO íŒ€ë³„ íˆ¬ìˆ˜ ê³ ê¸‰ ê¸°ë¡ ìŠ¤í¬ë˜í•‘ (ì™„íˆ¬, ì™„ë´‰, í€„ë¦¬í‹°ìŠ¤íƒ€íŠ¸ ë“±)"""
    url = "https://www.koreabaseball.com/Record/Team/Pitcher/Basic2.aspx"
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        table = soup.find('table', class_='tEx') or soup.find('table')
        
        if table is None:
            st.error("íˆ¬ìˆ˜ ê³ ê¸‰ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        rows = table.find_all('tr')
        data = []
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            row_text = [cell.get_text().strip() for cell in cells]
            
            # íŒ€ëª…ì´ í¬í•¨ëœ í–‰ì¸ì§€ í™•ì¸
            team_found = False
            for text in row_text:
                if text in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                    team_found = True
                    break
            
            if team_found and len(row_text) >= 16:  # íŒ€ëª… + ìµœì†Œ 15ê°œ ì§€í‘œ
                team_data = []
                # íŒ€ëª… ì°¾ê¸°
                for text in row_text:
                    if text in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                        team_data.append(text)
                        break
                
                # ë‚˜ë¨¸ì§€ ë°ì´í„° ì¶”ì¶œ (ERA, CG, SHO, QS, BSV, TBF, NP, AVG, 2B, 3B, SAC, SF, IBB, WP, BK)
                data_started = False
                for val in row_text:
                    if data_started and len(team_data) < 16:  # íŒ€ëª… + 15ê°œ ì§€í‘œ
                        try:
                            if '.' in val and val.replace('.', '').replace('-', '').isdigit():
                                team_data.append(float(val))
                            elif val.replace('-', '').isdigit():
                                team_data.append(int(val))
                            else:
                                team_data.append(val)
                        except:
                            team_data.append(val)
                    elif val in ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']:
                        data_started = True
                
                if len(team_data) == 16:  # íŒ€ëª… + 15ê°œ ì§€í‘œ
                    data.append(team_data)
        
        if not data:
            st.error("íŒ€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        columns = ['íŒ€ëª…', 'ERA', 'CG', 'SHO', 'QS', 'BSV', 'TBF', 'NP', 'AVG', '2B', '3B', 'SAC', 'SF', 'IBB', 'WP', 'BK']
        df = pd.DataFrame(data, columns=columns)
        df = df.sort_values('ERA', ascending=True).reset_index(drop=True)
        df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
        
        return df
        
    except Exception as e:
        st.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

@st.cache_data(ttl=3600)
def scrape_kbo_standings():
    """KBO íŒ€ ìˆœìœ„ ìŠ¤í¬ë˜í•‘"""
    url = "https://www.koreabaseball.com/Record/TeamRank/TeamRankDaily.aspx"
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ê¸°ì¤€ ë‚ ì§œ ì¶”ì¶œ
        date_info = None
        
        # í˜ì´ì§€ì—ì„œ ë‚ ì§œ ì •ë³´ ì°¾ê¸°
        all_texts = soup.get_text()
        lines = all_texts.split('\n')
        for line in lines:
            line = line.strip()
            if 'ê¸°ì¤€' in line and ('ë…„' in line and 'ì›”' in line):
                date_info = line
                break
        
        # ëŒ€ì•ˆ: íŠ¹ì • íŒ¨í„´ìœ¼ë¡œ ë‚ ì§œ ì°¾ê¸°
        if not date_info:
            import re
            date_pattern = r'\([0-9]{4}ë…„\s*[0-9]{2}ì›”[0-9]{2}ì¼\s*ê¸°ì¤€\)'
            matches = re.findall(date_pattern, all_texts)
            if matches:
                date_info = matches[0]
        
        table = soup.find('table', class_='tEx') or soup.find('table')
        
        if table is None:
            st.error("ìˆœìœ„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, date_info
            
        rows = table.find_all('tr')
        data = []
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            row_text = [cell.get_text().strip() for cell in cells]
            
            for j, text in enumerate(row_text):
                if text in ['LG', 'í•œí™”', 'ë¡¯ë°', 'ì‚¼ì„±', 'SSG', 'NC', 'KIA', 'ë‘ì‚°', 'KT', 'í‚¤ì›€']:
                    if len(row_text) >= 10:
                        team_data = []
                        team_data.append(text)
                        
                        for k in range(j+1, min(j+8, len(row_text))):
                            try:
                                val = row_text[k]
                                if '.' in val and val.replace('.', '').replace('-', '').isdigit():
                                    team_data.append(float(val))
                                elif val.replace('-', '').isdigit():
                                    team_data.append(int(val))
                                else:
                                    team_data.append(val)
                            except:
                                team_data.append(row_text[k])
                        
                        if len(team_data) == 8:
                            data.append(team_data)
                    break
        
        if not data:
            st.error("íŒ€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, date_info
        
        columns = ['íŒ€ëª…', 'ê²½ê¸°', 'ìŠ¹', 'íŒ¨', 'ë¬´', 'ìŠ¹ë¥ ', 'ê²Œì„ì°¨', 'ìµœê·¼10ê²½ê¸°']
        df = pd.DataFrame(data, columns=columns)
        df = df.sort_values('ìŠ¹ë¥ ', ascending=False).reset_index(drop=True)
        df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
        
        return df, date_info
        
    except Exception as e:
        st.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

def monte_carlo_simulation(win_probability, remaining_games, num_simulations=10000):
    """ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ ê¸°ëŒ€ ìŠ¹ìˆ˜ ê³„ì‚°"""
    total_wins = 0
    
    for _ in range(num_simulations):
        wins = 0
        for _ in range(remaining_games):
            if random.random() < win_probability:
                wins += 1
        total_wins += wins
    
    return total_wins / num_simulations

def calculate_championship_probability(teams_data, num_simulations=100000):
    """ê° íŒ€ì˜ ìš°ìŠ¹ í™•ë¥ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    championship_wins = {team: 0 for team in teams_data['íŒ€ëª…']}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for simulation in range(num_simulations):
        if simulation % 10000 == 0:
            progress = simulation / num_simulations
            progress_bar.progress(progress)
            status_text.text(f"ìš°ìŠ¹ í™•ë¥  ê³„ì‚° ì¤‘... {simulation:,}/{num_simulations:,} ({progress:.1%})")
        
        final_wins = {}
        
        for _, team in teams_data.iterrows():
            team_name = team['íŒ€ëª…']
            current_wins = team['ìŠ¹']
            pythagorean_wpct = team['p_wpct']
            remaining_games = team['ì”ì—¬ê²½ê¸°']
            
            simulated_wins = 0
            for _ in range(remaining_games):
                if random.random() < pythagorean_wpct:
                    simulated_wins += 1
            
            final_wins[team_name] = current_wins + simulated_wins
        
        champion = max(final_wins, key=final_wins.get)
        championship_wins[champion] += 1
    
    progress_bar.progress(1.0)
    status_text.text("ìš°ìŠ¹ í™•ë¥  ê³„ì‚° ì™„ë£Œ!")
    
    championship_probabilities = {}
    for team, wins in championship_wins.items():
        championship_probabilities[team] = (wins / num_simulations) * 100
    
    return championship_probabilities

def calculate_playoff_probability(teams_data, num_simulations=50000):
    """í”Œë ˆì´ì˜¤í”„ ì§„ì¶œ í™•ë¥  ê³„ì‚° (ìƒìœ„ 5íŒ€)"""
    playoff_wins = {team: 0 for team in teams_data['íŒ€ëª…']}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for simulation in range(num_simulations):
        if simulation % 10000 == 0:
            progress = simulation / num_simulations
            progress_bar.progress(progress)
            status_text.text(f"í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì¤‘... {simulation:,}/{num_simulations:,} ({progress:.1%})")
        
        final_wins = {}
        
        for _, team in teams_data.iterrows():
            team_name = team['íŒ€ëª…']
            current_wins = team['ìŠ¹']
            pythagorean_wpct = team['p_wpct']
            remaining_games = team['ì”ì—¬ê²½ê¸°']
            
            simulated_wins = 0
            for _ in range(remaining_games):
                if random.random() < pythagorean_wpct:
                    simulated_wins += 1
            
            final_wins[team_name] = current_wins + simulated_wins
        
        sorted_teams = sorted(final_wins.items(), key=lambda x: x[1], reverse=True)
        playoff_teams = [team[0] for team in sorted_teams[:5]]
        
        for team in playoff_teams:
            playoff_wins[team] += 1
    
    progress_bar.progress(1.0)
    status_text.text("í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì™„ë£Œ!")
    
    playoff_probabilities = {}
    for team, wins in playoff_wins.items():
        playoff_probabilities[team] = (wins / num_simulations) * 100
    
    return playoff_probabilities

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">âš¾ KBO íŒ€ í†µê³„ ë¶„ì„ê¸°</h1>', unsafe_allow_html=True)
    
    # ë°ì´í„° ë¡œë”©
    with st.spinner("ì‹¤ì‹œê°„ KBO ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        df_hitter = scrape_kbo_team_batting_stats()
        df_hitter_advanced = scrape_kbo_team_batting_stats_advanced()
        df_pitcher = scrape_kbo_team_pitching_stats()
        df_pitcher_advanced = scrape_kbo_team_pitching_stats_advanced()
        df_standings, date_info = scrape_kbo_standings()
    
    if df_hitter is None or df_hitter_advanced is None or df_pitcher is None or df_pitcher_advanced is None or df_standings is None:
        st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return
    
    # ê¸°ì¤€ ë‚ ì§œ í‘œì‹œ (ë°ì´í„° ë¡œë”© í›„)
    if date_info:
        st.markdown(f'<p style="text-align: center; font-size: 1rem; color: #666; margin-top: -1rem; margin-bottom: 2rem;">{date_info}</p>', unsafe_allow_html=True)
    
    # íƒ€ì ê¸°ë¡ ê²°í•© (íŒ€ëª… ê¸°ì¤€)
    df_hitter_combined = pd.merge(df_hitter, df_hitter_advanced[['íŒ€ëª…', 'BB', 'IBB', 'HBP', 'SO', 'GDP', 'SLG', 'OBP', 'OPS', 'MH', 'RISP']], 
                                 on='íŒ€ëª…', how='left')
    
    # íˆ¬ìˆ˜ ê¸°ë¡ ê²°í•© (íŒ€ëª… ê¸°ì¤€)
    df_pitcher_combined = pd.merge(df_pitcher, df_pitcher_advanced[['íŒ€ëª…', 'CG', 'SHO', 'QS', 'BSV', 'TBF', 'NP', 'AVG', '2B', '3B', 'SAC', 'SF', 'IBB', 'WP', 'BK']], 
                                  on='íŒ€ëª…', how='left')
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ˆ í˜„ì¬ ìˆœìœ„", "ğŸŸï¸ íŒ€ë³„ ê¸°ë¡", "ğŸ“Š ì‹œê°í™”", "ğŸ† ìš°ìŠ¹ í™•ë¥ ", "ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥"])
    
    with tab1:
        st.header("ğŸ“ˆ í˜„ì¬ ìˆœìœ„")
        # í˜„ì¬ ìˆœìœ„ í‘œì‹œ
        # st.subheader("í˜„ì¬ ìˆœìœ„")
        # st.dataframe(df_standings, use_container_width=True, hide_index=True)
        
        # with col2:
        #     st.subheader("ìŠ¹ë¥  ë¶„í¬")
        #     # ìŠ¹ë¥  ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        #     df_sorted = df_standings.sort_values('ìŠ¹ë¥ ', ascending=False)
        #     # st.write(df_sorted)
        #     fig = px.bar(df_sorted, y='íŒ€ëª…', x='ìŠ¹ë¥ ', 
        #                 # title="íŒ€ë³„ ìŠ¹ë¥ ",
        #                 color='ìŠ¹ë¥ ',
        #                 color_continuous_scale='RdYlGn',
        #                 orientation='h')
        #     fig.update_layout(xaxis_tickangle=0, showlegend=False)
        #     fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
        #     fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
        #     st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.header("ğŸŸï¸ íŒ€ë³„ ê¸°ë¡")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("íƒ€ì ê¸°ë¡")
            df_hitter_clean = clean_dataframe_for_display(df_hitter_combined)
            safe_dataframe_display(df_hitter_clean, use_container_width=True, hide_index=True)
        
        with col2:
            st.subheader("íˆ¬ìˆ˜ ê¸°ë¡")
            df_pitcher_clean = clean_dataframe_for_display(df_pitcher_combined)
            safe_dataframe_display(df_pitcher_clean, use_container_width=True, hide_index=True)
        
        # Top 3 íŒ€ë“¤ì„ 2ì—´ë¡œ ë°°ì¹˜
        st.subheader("ğŸ† TOP 3 íŒ€")
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("íƒ€ê²© ìƒìœ„ 3íŒ€")
            # íƒ€ìœ¨ ìƒìœ„ 3íŒ€
            top3_avg = df_hitter_combined.nlargest(3, 'AVG')[['íŒ€ëª…', 'AVG']]
            st.write("**íƒ€ìœ¨ ìƒìœ„ 3íŒ€**")
            col1_1, col1_2, col1_3 = st.columns(3)
            for i, (idx, row) in enumerate(top3_avg.iterrows()):
                if i == 0:
                    with col1_1:
                        st.metric(f"1ìœ„ {row['íŒ€ëª…']}", f"{row['AVG']:.3f}")
                elif i == 1:
                    with col1_2:
                        st.metric(f"2ìœ„ {row['íŒ€ëª…']}", f"{row['AVG']:.3f}")
                else:
                    with col1_3:
                        st.metric(f"3ìœ„ {row['íŒ€ëª…']}", f"{row['AVG']:.3f}")
            
            # OPS ìƒìœ„ 3íŒ€
            top3_ops = df_hitter_combined.nlargest(3, 'OPS')[['íŒ€ëª…', 'OPS']]
            st.write("**OPS ìƒìœ„ 3íŒ€**")
            col1_4, col1_5, col1_6 = st.columns(3)
            for i, (idx, row) in enumerate(top3_ops.iterrows()):
                if i == 0:
                    with col1_4:
                        st.metric(f"1ìœ„ {row['íŒ€ëª…']}", f"{row['OPS']:.3f}")
                elif i == 1:
                    with col1_5:
                        st.metric(f"2ìœ„ {row['íŒ€ëª…']}", f"{row['OPS']:.3f}")
                else:
                    with col1_6:
                        st.metric(f"3ìœ„ {row['íŒ€ëª…']}", f"{row['OPS']:.3f}")
        
        with col2:
            st.subheader("íˆ¬ìˆ˜ ìƒìœ„ 3íŒ€")
            # ERA ìƒìœ„ 3íŒ€
            top3_era = df_pitcher_combined.nsmallest(3, 'ERA')[['íŒ€ëª…', 'ERA']]
            st.write("**ERA ìƒìœ„ 3íŒ€ (ë‚®ì€ ìˆœ)**")
            col2_1, col2_2, col2_3 = st.columns(3)
            for i, (idx, row) in enumerate(top3_era.iterrows()):
                if i == 0:
                    with col2_1:
                        st.metric(f"1ìœ„ {row['íŒ€ëª…']}", f"{row['ERA']:.2f}")
                elif i == 1:
                    with col2_2:
                        st.metric(f"2ìœ„ {row['íŒ€ëª…']}", f"{row['ERA']:.2f}")
                else:
                    with col2_3:
                        st.metric(f"3ìœ„ {row['íŒ€ëª…']}", f"{row['ERA']:.2f}")
            
            # WHIP ìƒìœ„ 3íŒ€
            top3_whip = df_pitcher_combined.nsmallest(3, 'WHIP')[['íŒ€ëª…', 'WHIP']]
            st.write("**WHIP ìƒìœ„ 3íŒ€ (ë‚®ì€ ìˆœ)**")
            col2_4, col2_5, col2_6 = st.columns(3)
            for i, (idx, row) in enumerate(top3_whip.iterrows()):
                if i == 0:
                    with col2_4:
                        st.metric(f"1ìœ„ {row['íŒ€ëª…']}", f"{row['WHIP']:.2f}")
                elif i == 1:
                    with col2_5:
                        st.metric(f"2ìœ„ {row['íŒ€ëª…']}", f"{row['WHIP']:.2f}")
                else:
                    with col2_6:
                        st.metric(f"3ìœ„ {row['íŒ€ëª…']}", f"{row['WHIP']:.2f}")
    
    with tab1:
        # st.header("ğŸ“ˆ í˜„ì¬ ìˆœìœ„")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥  ê³„ì‚° ë° ê¸°ë³¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        df_runs = pd.merge(df_hitter[['íŒ€ëª…', 'R']], df_pitcher[['íŒ€ëª…', 'R']], on='íŒ€ëª…', how='left')
        df_runs.rename(columns={'R_x': 'R', 'R_y': 'RA'}, inplace=True)
        
        p_n = 1.834
        df_runs['p_wpct'] = df_runs['R']**p_n / (df_runs['R']**p_n + df_runs['RA']**p_n)
        df_runs['p_wpct'] = df_runs['p_wpct'].round(4)
        
        df_final = pd.merge(df_standings, df_runs, on='íŒ€ëª…', how='left')
        df_final['ì”ì—¬ê²½ê¸°'] = 144 - df_final['ê²½ê¸°']
        
        # ê¸°ë³¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
        np.random.seed(42)
        random.seed(42)
        
        simulation_results = []
        for _, row in df_final.iterrows():
            team_name = row['íŒ€ëª…']
            current_wins = row['ìŠ¹']
            win_rate = row['ìŠ¹ë¥ ']
            pythagorean_wpct = row['p_wpct']
            remaining_games = row['ì”ì—¬ê²½ê¸°']
            
            expected_wins_winrate = monte_carlo_simulation(win_rate, remaining_games, 10000)
            expected_wins_pythagorean = monte_carlo_simulation(pythagorean_wpct, remaining_games, 10000)
            
            final_expected_wins_winrate = current_wins + expected_wins_winrate
            final_expected_wins_pythagorean = current_wins + expected_wins_pythagorean
            
            simulation_results.append({
                'íŒ€ëª…': team_name,
                'í˜„ì¬ìŠ¹ìˆ˜': current_wins,
                'ì”ì—¬ê²½ê¸°': remaining_games,
                'ìŠ¹ë¥ ': win_rate,
                'p_wpct': pythagorean_wpct,
                'ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜': expected_wins_winrate,
                'ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜': expected_wins_pythagorean,
                'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜': final_expected_wins_winrate,
                'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜': final_expected_wins_pythagorean
            })
        
        results_df = pd.DataFrame(simulation_results)
        df_final = df_final.merge(results_df[['íŒ€ëª…', 'ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜', 'ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜', 
                                            'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜', 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜']], 
                                on='íŒ€ëª…', how='left')
        
        # df_finalì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥
        st.session_state['df_final'] = df_final
        
        # í˜„ì¬ ìˆœìœ„ì™€ ì˜ˆì¸¡ ë¶„ì„ í‘œì‹œ
        st.subheader("ğŸ“Š í˜„ì¬ ìˆœìœ„ ë° ì˜ˆì¸¡ ë¶„ì„")
        
        # í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥ ê³¼ ìµœì¢… ê¸°ëŒ€ìŠ¹ìˆ˜ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_display = df_final[['ìˆœìœ„', 'íŒ€ëª…', 'ê²½ê¸°', 'ìŠ¹', 'íŒ¨', 'ë¬´', 'ìŠ¹ë¥ ', 'ê²Œì„ì°¨', 'ìµœê·¼10ê²½ê¸°',
                              'p_wpct', 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜']].copy()
        df_display['p_wpct'] = df_display['p_wpct'].round(4)
        df_display['ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜'] = df_display['ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜'].round(1)
        df_display.rename(columns={'p_wpct': 'í”¼íƒ€ê³ ë¦¬ì•ˆìŠ¹ë¥ ', 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜': 'ì˜ˆìƒìµœì¢…ìŠ¹ìˆ˜'}, inplace=True)
        
        df_display_clean = clean_dataframe_for_display(df_display)
        safe_dataframe_display(df_display_clean, use_container_width=True, hide_index=True)
    
    with tab3:
        st.header("ğŸ“Š ì‹œê°í™”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # íƒ€ìœ¨ vs í™ˆëŸ°
            fig1 = px.scatter(df_hitter_combined, x='AVG', y='HR', 
                             title="íƒ€ìœ¨ vs í™ˆëŸ°",
                             hover_data=['íŒ€ëª…'],
                             text='íŒ€ëª…')
            fig1.update_traces(textposition="top center", marker_size=12)
            fig1.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig1.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            # ERA vs ì‚¼ì§„
            fig2 = px.scatter(df_pitcher_combined, x='ERA', y='SO', 
                             title="ERA vs ì‚¼ì§„",
                             hover_data=['íŒ€ëª…'],
                             text='íŒ€ëª…')
            fig2.update_traces(textposition="top center", marker_size=12)
            fig2.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig2.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            st.plotly_chart(fig2, use_container_width=True)
        
        # ìŠ¹ë¥  vs í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥  ë¹„êµ
        df_final = st.session_state['df_final']
        fig3 = px.scatter(df_final, x='ìŠ¹ë¥ ', y='p_wpct', 
                         title="ì‹¤ì œ ìŠ¹ë¥  vs í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥ ",
                         hover_data=['íŒ€ëª…'],
                         text='íŒ€ëª…')
        fig3.add_trace(go.Scatter(x=[0.250, 0.650], y=[0.250, 0.650], mode='lines', 
                                 name='ê¸°ì¤€ì„ ', line=dict(dash='dash', color='red')))
        fig3.update_traces(textposition="top center", marker_size=12)
        fig3.update_xaxes(range=[0.250, 0.650], showgrid=True, gridwidth=1, gridcolor='lightgray')
        fig3.update_yaxes(range=[0.250, 0.650], showgrid=True, gridwidth=1, gridcolor='lightgray')
        st.plotly_chart(fig3, use_container_width=True)
    
    with tab4:
        # st.header("ğŸ† ìš°ìŠ¹ í™•ë¥ ")
        
        df_final = st.session_state['df_final']
        # st.subheader("ìš°ìŠ¹ í™•ë¥  ê³„ì‚°")
        
        # ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜ ì„¤ì •
        col1, col2 = st.columns(2)
        with col1:
            championship_simulations = st.slider("ìš°ìŠ¹ í™•ë¥  ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", 5000, 50000, 5000, step=5000)
        with col2:
            playoff_simulations = st.slider("í”Œë ˆì´ì˜¤í”„ í™•ë¥  ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", 5000, 50000, 5000, step=5000)
        
        if st.button("ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
            with st.spinner("ìš°ìŠ¹ í™•ë¥ ê³¼ í”Œë ˆì´ì˜¤í”„ í™•ë¥ ì„ ê³„ì‚°í•˜ëŠ” ì¤‘..."):
                # ìš°ìŠ¹ í™•ë¥  ê³„ì‚°
                championship_probs = calculate_championship_probability(df_final, championship_simulations)
                df_final['ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸'] = df_final['íŒ€ëª…'].map(championship_probs)
                
                # í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚°
                playoff_probs = calculate_playoff_probability(df_final, playoff_simulations)
                df_final['í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸'] = df_final['íŒ€ëª…'].map(playoff_probs)

                # Google Sheetsì— ì €ì¥ ì‹œë„
                log_df = df_final[['íŒ€ëª…', 'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', 'í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸']].copy()
                append_simulation_to_sheet(log_df, "SimulationLog")
                
                # ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìŠ¹ìˆ˜ë¡œ ëŒ€ì²´
                display_col = 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜' if 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜' in df_final.columns else 'ìŠ¹'
                
                # í†µí•© ê²°ê³¼ í…Œì´ë¸” ìƒì„±
                combined_df = df_final[['ìˆœìœ„', 'íŒ€ëª…', display_col, 'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', 'í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸']].copy()
                combined_df = combined_df.sort_values('ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', ascending=False).reset_index(drop=True)
                combined_df.rename(columns={display_col: 'ì˜ˆìƒìµœì¢…ìŠ¹ìˆ˜'}, inplace=True)
                
                st.subheader("ğŸ† KBO ìš°ìŠ¹ í™•ë¥  & PO ì§„ì¶œ í™•ë¥ ")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    combined_df_clean = clean_dataframe_for_display(combined_df)
                    combined_df_clean.rename(columns={'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸': 'ìš°ìŠ¹í™•ë¥ '}, inplace=True)
                    combined_df_clean.rename(columns={'í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸': 'POí™•ë¥ '}, inplace=True)
                    safe_dataframe_display(combined_df_clean, use_container_width=True, hide_index=True)
                
                with col2:
                    # ìš°ìŠ¹ í™•ë¥  ì‹œê°í™”
                    fig = px.bar(combined_df, x='íŒ€ëª…', y='ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸',
                                title="íŒ€ë³„ ìš°ìŠ¹ í™•ë¥ ",
                                color='ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸',
                                color_continuous_scale='RdYlGn')
                    fig.update_layout(xaxis_tickangle=-45)
                    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                    st.plotly_chart(fig, use_container_width=True)
                
                # í”Œë ˆì´ì˜¤í”„ í™•ë¥  ì‹œê°í™”
                fig2 = px.bar(combined_df, x='íŒ€ëª…', y='í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸',
                             title="íŒ€ë³„ í”Œë ˆì´ì˜¤í”„ ì§„ì¶œ í™•ë¥ ",
                             color='í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸',
                             color_continuous_scale='Blues')
                fig2.update_layout(xaxis_tickangle=-45)
                fig2.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                fig2.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                st.plotly_chart(fig2, use_container_width=True)

    with tab5:
        st.header("ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥")
    # with st.expander("ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ ë¶„ì„"):
        try:
            client = get_gsheet_client()
            if client is None:
                st.info("Google Sheets ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.warning("ì§„ë‹¨ ì •ë³´:\n" + _diagnose_gsheet_setup())
            else:
                worksheet = client.open("KBO_Simulation_Log").worksheet("SimulationLog")
                history = worksheet.get_all_records()
                df_history = pd.DataFrame(history)

                if not df_history.empty:
                    df_history['timestamp'] = pd.to_datetime(df_history['timestamp'])

                    df_summary = df_history.groupby(['timestamp']).agg({
                        'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸': 'mean',
                        'í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸': 'mean'
                    }).reset_index()

                    fig = px.line(df_summary, x='timestamp', y=['ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', 'í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸'],
                                  title='ì¼ìë³„ í‰ê·  ìš°ìŠ¹ / í”Œë ˆì´ì˜¤í”„ í™•ë¥ ', markers=True)
                    fig.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title="í™•ë¥ (%)")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("ì•„ì§ ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ìš°ìŠ¹ í™•ë¥  íƒ­ì—ì„œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
        except Exception as e:
            st.info("Google Sheets ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # Google Sheets ì—°ê²° ì‹¤íŒ¨ ì‹œì—ë„ ì•±ì´ ê³„ì† ì‘ë™í•˜ë„ë¡ í•¨
            pass


if __name__ == "__main__":
    main() 
