# kbo_teamstat_streamlit.py
from io import StringIO
import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import gspread
from gspread.exceptions import APIError as GspreadAPIError
from google.oauth2.service_account import Credentials
import plotly.express as px
import plotly.graph_objects as go

# -----------------------------
# í˜ì´ì§€/ìŠ¤íƒ€ì¼
# -----------------------------
st.set_page_config(
    page_title="KBO íŒ€ í†µê³„ ë¶„ì„ê¸°",
    page_icon="âš¾",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.markdown("""
<style>
    .main-header { font-size: 2.5rem; color: #1f77b4; text-align: center; margin-bottom: 2rem; }
    .metric-card { background-color: #f0f2f6; padding: 1rem; border-radius: .5rem; border-left: 4px solid #1f77b4; }
    .team-stats { background-color: #fff; padding: 1rem; border-radius: .5rem; box-shadow: 0 2px 4px rgba(0,0,0,.1); }
</style>
""", unsafe_allow_html=True)

# -----------------------------
# ìƒìˆ˜/ìœ í‹¸
# -----------------------------
TEAM_NAMES = ['ë¡¯ë°', 'ì‚¼ì„±', 'LG', 'í•œí™”', 'KIA', 'ë‘ì‚°', 'NC', 'KT', 'SSG', 'í‚¤ì›€']
HEADERS = {'User-Agent': 'Mozilla/5.0'}

def _diagnose_gsheet_setup() -> str:
    msgs = []
    try:
        if "gcp_service_account" not in st.secrets:
            msgs.append("- secretsì— [gcp_service_account] ì„¹ì…˜ì´ ì—†ìŒ (.streamlit/secrets.toml í™•ì¸)")
            return "\n".join(msgs)

        gcp = dict(st.secrets["gcp_service_account"])
        required = ["type","project_id","private_key_id","private_key","client_email","client_id","token_uri"]
        missing = [k for k in required if k not in gcp or not gcp[k]]
        if missing:
            msgs.append(f"- ëˆ„ë½ëœ í‚¤: {', '.join(missing)}")

        pk = str(gcp.get("private_key", ""))
        if not pk.startswith("-----BEGIN PRIVATE KEY-----"):
            msgs.append("- private_key í˜•ì‹ ì˜¤ë¥˜: PEM í—¤ë”ê°€ ì—†ìŒ")
        if "\\n" not in gcp.get("private_key", "") and "\n" not in pk:
            msgs.append("- private_key ì¤„ë°”ê¿ˆ ëˆ„ë½ ê°€ëŠ¥ì„±: TOMLì—” \\në¡œ ì €ì¥ í•„ìš”")
        email = str(gcp.get("client_email",""))
        if not email.endswith("iam.gserviceaccount.com"):
            msgs.append("- client_email ê°’ì´ ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹˜")
        if not msgs:
            msgs.append("- secrets í˜•ì‹ì€ ì •ìƒ. Sheets/Drive API í™œì„±í™” ë° ëŒ€ìƒ ì‹œíŠ¸ ê³µìœ  ê¶Œí•œ í™•ì¸")
    except Exception as e:
        msgs.append(f"- ì§„ë‹¨ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    return "\n".join(msgs)

def _format_gspread_error(err: Exception) -> str:
    try:
        if isinstance(err, GspreadAPIError):
            status_code, reason, message = None, None, None
            resp = getattr(err, "response", None)
            if resp is not None:
                status_code = getattr(resp, "status_code", None)
                try:
                    data = resp.json()
                    err_obj = data.get("error", {}) if isinstance(data, dict) else {}
                    message = err_obj.get("message")
                    details = err_obj.get("errors") or []
                    if isinstance(details, list) and details:
                        reason = details[0].get("reason")
                except Exception:
                    message = getattr(resp, "text", None)
            parts = []
            if status_code is not None: parts.append(f"status={status_code}")
            if reason: parts.append(f"reason={reason}")
            if message: parts.append(f"message={message}")
            return "; ".join(parts) if parts else str(err)
        return str(err)
    except Exception:
        return str(err)

def get_gsheet_client():
    try:
        scope = ["https://www.googleapis.com/auth/spreadsheets","https://www.googleapis.com/auth/drive"]
        if "gcp_service_account" not in st.secrets:
            st.error("Streamlit secretsì— 'gcp_service_account' ì—†ìŒ")
            return None

        gcp = dict(st.secrets["gcp_service_account"])
        required = ["type","project_id","private_key_id","private_key","client_email","client_id","token_uri"]
        missing = [k for k in required if k not in gcp or not gcp[k]]
        if missing:
            st.error(f"gcp_service_account ëˆ„ë½ í‚¤: {', '.join(missing)}")
            return None

        pk = gcp.get("private_key","")
        if isinstance(pk, str):
            pk = pk.replace("\\r\\n","\n").replace("\\n","\n").replace("\\r","\n")
        if not str(pk).startswith("-----BEGIN PRIVATE KEY-----"):
            st.error("gcp_service_account.private_key í˜•ì‹ ì˜¤ë¥˜(PEM í—¤ë” ëˆ„ë½)")
            return None
        gcp["private_key"] = pk

        try:
            creds = Credentials.from_service_account_info(gcp, scopes=scope)
        except Exception as e:
            st.error(f"ì„œë¹„ìŠ¤ ê³„ì • ìê²© ì¦ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return None

        try:
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"gspread ì¸ì¦ ì‹¤íŒ¨: {e}")
            return None
    except Exception as e:
        st.error(f"Google Sheets ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def _extract_sheet_id_from_url(url: str) -> str | None:
    try:
        m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", str(url))
        return m.group(1) if m else None
    except Exception:
        return None

def append_simulation_to_sheet(df_result: pd.DataFrame, sheet_name="SimulationLog"):
    try:
        client = get_gsheet_client()
        if client is None:
            st.error("êµ¬ê¸€ ì‹œíŠ¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì›ì¸ ì§„ë‹¨:\n" + _diagnose_gsheet_setup())
            return

        cfg = {}
        try:
            cfg = st.secrets.get("gsheet", {}) or {}
        except Exception:
            pass

        spreadsheet_id = cfg.get("spreadsheet_id")
        spreadsheet_url = cfg.get("spreadsheet_url")
        if not spreadsheet_id and spreadsheet_url:
            spreadsheet_id = _extract_sheet_id_from_url(spreadsheet_url)

        if spreadsheet_id:
            try:
                sh = client.open_by_key(spreadsheet_id)
            except Exception as e:
                st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸(ID) ì—´ê¸° ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                return
        else:
            try:
                sh = client.open("KBO_Simulation_Log")
            except Exception:
                try:
                    sh = client.create("KBO_Simulation_Log")
                except Exception as e:
                    txt = str(e)
                    if "quota" in txt.lower() and "storage" in txt.lower():
                        st.error(
                            "Google Drive ì €ì¥ ìš©ëŸ‰ ì´ˆê³¼ë¡œ ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                            "- ë“œë¼ì´ë¸Œ ìš©ëŸ‰ í™•ë³´(íœ´ì§€í†µ ë¹„ìš°ê¸° í¬í•¨) í›„ ì¬ì‹œë„\n"
                            "- ë˜ëŠ” ê¸°ì¡´ ì‹œíŠ¸ IDë¥¼ secrets.gsheet.spreadsheet_idì— ì„¤ì • + ì„œë¹„ìŠ¤ ê³„ì •ì— í¸ì§‘ì ê³µìœ "
                        )
                    else:
                        st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                    return

        created_new_ws = False
        try:
            ws = sh.worksheet(sheet_name)
        except Exception:
            try:
                ws = sh.add_worksheet(title=sheet_name, rows="10000", cols="50")
                created_new_ws = True
            except Exception as e:
                st.error("ì›Œí¬ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨:\n" + _format_gspread_error(e))
                return

        df_out = df_result.copy()
        df_out.insert(0, "timestamp", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

        if created_new_ws:
            try:
                ws.append_row(df_out.columns.tolist(), value_input_option="USER_ENTERED")
            except Exception as e:
                st.warning("í—¤ë” ì¶”ê°€ ì‹¤íŒ¨(ê³„ì† ì§„í–‰):\n" + _format_gspread_error(e))

        try:
            ws.append_rows(df_out.values.tolist(), value_input_option="USER_ENTERED")
        except Exception as e:
            st.error("ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨:\n" + _format_gspread_error(e))
            return

        st.success(f"ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ '{sheet_name}' ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error("Google Sheets ì €ì¥ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜:\n" + _format_gspread_error(e))

def safe_dataframe_display(df: pd.DataFrame, use_container_width=True, hide_index=True):
    try:
        df_display = df.copy()
        for c in df_display.columns:
            try:
                df_display[c] = df_display[c].astype(str)
            except Exception:
                pass
        st.dataframe(df_display, use_container_width=use_container_width, hide_index=hide_index)
    except Exception as e:
        st.error(f"ë°ì´í„°í”„ë ˆì„ í‘œì‹œ ì˜¤ë¥˜: {e}")
        st.write("ì›ë³¸ í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤:")
        st.write(df)

def normalize_team_names(df: pd.DataFrame, col: str = "íŒ€ëª…") -> pd.DataFrame:
    """íŒ€ëª… ì»¬ëŸ¼ ê³µë°±/ë¹„ê°€ì‹œë¬¸ì ì œê±° ë° í‘œì¤€í™”."""
    if df is not None and not df.empty and col in df.columns:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(r"\s+", "", regex=True)
            .str.strip()
        )
    return df

def clean_dataframe_for_display(df: pd.DataFrame) -> pd.DataFrame:
    """í‘œì‹œìš© ì •ë¦¬: IP ë¬¸ìì—´ ìœ ì§€, ìˆ˜ì¹˜ ì»¬ëŸ¼ ë°˜ì˜¬ë¦¼ í›„ ë¬¸ìì—´í™”(Arrow í˜¸í™˜)."""
    try:
        dfc = df.copy()
        if "IP" in dfc.columns:
            dfc["IP"] = dfc["IP"].astype(str)

        for c in dfc.columns:
            if c in ("íŒ€ëª…", "ìˆœìœ„", "ìµœê·¼10ê²½ê¸°"):
                continue
            try:
                dfc[c] = pd.to_numeric(dfc[c])
            except Exception:
                continue

        for c in dfc.columns:
            if c in ("íŒ€ëª…", "ìˆœìœ„", "ìµœê·¼10ê²½ê¸°"):
                continue
            if pd.api.types.is_float_dtype(dfc[c]):
                dfc[c] = dfc[c].round(3).astype(str)
            elif pd.api.types.is_integer_dtype(dfc[c]):
                dfc[c] = dfc[c].astype(str)

        return dfc
    except Exception as e:
        st.error(f"í‘œì‹œ ì •ë¦¬ ì˜¤ë¥˜: {e}")
        return df

def _parse_ip_to_decimal(ip_str: str) -> float | None:
    """'123 2/3' ë˜ëŠ” '123.1' ê°™ì€ ì´ë‹ ë¬¸ìì—´ì„ ì†Œìˆ˜ë¡œ ë³€í™˜(íˆ¬ìˆ˜ IPëŠ” ë³´í†µ 1/3 ë‹¨ìœ„)."""
    if ip_str is None:
        return None
    s = str(ip_str).strip()
    if not s:
        return None
    m = re.match(r"^(\d+)\s+(\d)\/3$", s)
    if m:
        whole = float(m.group(1)); frac = int(m.group(2))/3.0
        return round(whole + frac, 4)
    m2 = re.match(r"^(\d+)\.(\d)$", s)
    if m2:
        whole = float(m2.group(1)); tenths = int(m2.group(2))
        if tenths in (1,2):
            frac = tenths/3.0
            return round(whole + frac, 4)
        return float(s)
    try:
        return float(s)
    except Exception:
        return None

def _first_table_html(url: str) -> tuple[pd.DataFrame | None, BeautifulSoup | None]:
    """í•´ë‹¹ í˜ì´ì§€ì—ì„œ ì²« í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ ì½ê³ , soupë„ ë°˜í™˜."""
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        r.raise_for_status()
        soup = BeautifulSoup(r.content, "html.parser")
        # read_html ê²½ê³  ë°©ì§€: StringIOë¡œ ê°ì‹¼ literal HTML ì‚¬ìš©
        try:
            tables = pd.read_html(StringIO(r.text))
            if tables:
                return tables[0], soup
        except Exception:
            pass
        table = soup.find("table")
        if not table:
            return None, soup
        rows = []
        for tr in table.find_all("tr"):
            cells = tr.find_all(["th", "td"])
            if not cells:
                continue
            rows.append([c.get_text(strip=True) for c in cells])
        if not rows:
            return None, soup
        df = pd.DataFrame(rows[1:], columns=rows[0])
        return df, soup
    except Exception:
        return None, None

# -----------------------------
# ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
# -----------------------------
@st.cache_data(ttl=3600)
def scrape_kbo_team_batting_stats():
    url = "https://www.koreabaseball.com/Record/Team/Hitter/Basic1.aspx"
    df, _ = _first_table_html(url)
    if df is None or df.empty:
        st.error("íƒ€ì ê¸°ë³¸ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    df = df[df.iloc[:,0].isin(TEAM_NAMES)].copy()
    cols = ['íŒ€ëª…','AVG','G','PA','AB','R','H','2B','3B','HR','TB','RBI','SAC','SF']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    for c in df.columns:
        if c != 'íŒ€ëª…':
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('AVG', ascending=False).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', range(1, len(df)+1))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_team_batting_stats_advanced():
    url = "https://www.koreabaseball.com/Record/Team/Hitter/Basic2.aspx"
    df, _ = _first_table_html(url)
    if df is None or df.empty:
        st.error("íƒ€ì ê³ ê¸‰ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    df = df[df.iloc[:,0].isin(TEAM_NAMES)].copy()
    cols = ['íŒ€ëª…','AVG','BB','IBB','HBP','SO','GDP','SLG','OBP','OPS','MH','RISP']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    for c in df.columns:
        if c != 'íŒ€ëª…':
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('AVG', ascending=False).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', range(1, len(df)+1))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_team_pitching_stats():
    url = "https://www.koreabaseball.com/Record/Team/Pitcher/Basic1.aspx"
    df, _ = _first_table_html(url)
    if df is None or df.empty:
        st.error("íˆ¬ìˆ˜ ê¸°ë³¸ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    df = df[df.iloc[:,0].isin(TEAM_NAMES)].copy()
    cols = ['íŒ€ëª…','ERA','G','W','L','SV','HLD','WPCT','IP','H','HR','BB','HBP','SO','R','ER','WHIP']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    if 'IP' in df.columns:
        df['IP_decimal'] = df['IP'].apply(_parse_ip_to_decimal)
        df['IP'] = df['IP'].astype(str)
    for c in df.columns:
        if c not in ['íŒ€ëª…','IP']:
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('ERA', ascending=True).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', range(1, len(df)+1))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_team_pitching_stats_advanced():
    url = "https://www.koreabaseball.com/Record/Team/Pitcher/Basic2.aspx"
    df, _ = _first_table_html(url)
    if df is None or df.empty:
        st.error("íˆ¬ìˆ˜ ê³ ê¸‰ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    df = df[df.iloc[:,0].isin(TEAM_NAMES)].copy()
    cols = ['íŒ€ëª…','ERA','CG','SHO','QS','BSV','TBF','NP','AVG','2B','3B','SAC','SF','IBB','WP','BK']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    for c in df.columns:
        if c != 'íŒ€ëª…':
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('ERA', ascending=True).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', range(1, len(df)+1))
    return df

@st.cache_data(ttl=3600)
def scrape_kbo_standings():
    url = "https://www.koreabaseball.com/Record/TeamRank/TeamRankDaily.aspx"
    df, soup = _first_table_html(url)
    date_info = None
    if soup:
        all_texts = soup.get_text("\n")
        m = re.search(r"\(\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼\s*ê¸°ì¤€\)", all_texts)
        if m:
            date_info = m.group(0)
    if df is None or df.empty:
        st.error("ìˆœìœ„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, date_info
    df = df[df.iloc[:,0].isin(['LG','í•œí™”','ë¡¯ë°','ì‚¼ì„±','SSG','NC','KIA','ë‘ì‚°','KT','í‚¤ì›€'])].copy()
    cols = ['íŒ€ëª…','ê²½ê¸°','ìŠ¹','íŒ¨','ë¬´','ìŠ¹ë¥ ','ê²Œì„ì°¨','ìµœê·¼10ê²½ê¸°']
    take = min(len(df.columns), len(cols))
    df = df.iloc[:, :take].copy()
    df.columns = cols[:take]
    for c in ['ê²½ê¸°','ìŠ¹','íŒ¨','ë¬´','ìŠ¹ë¥ ']:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')
    df = df.sort_values('ìŠ¹ë¥ ', ascending=False).reset_index(drop=True)
    df.insert(0, 'ìˆœìœ„', range(1, len(df)+1))
    return df, date_info

# -----------------------------
# ì‹œë®¬ë ˆì´ì…˜(ê³ ì†/ì•ˆì „)
# -----------------------------
def monte_carlo_expected_wins(p: float, n_games: int, n_sims: int = 10_000) -> float:
    if n_games <= 0:
        return 0.0
    if p <= 0.0:
        return 0.0
    if p >= 1.0:
        return float(n_games)
    wins = np.random.binomial(n=n_games, p=float(p), size=n_sims)
    return float(wins.mean())

def calculate_championship_probability(teams_df: pd.DataFrame, num_simulations: int = 100_000) -> dict:
    """
    í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥  ê¸°ë°˜ ìš°ìŠ¹ í™•ë¥  ê³„ì‚°(ë¹ˆ DF/íŒ€ ìˆ˜ 0/ì”ì—¬ê²½ê¸° 0 ì „ë¶€ ë°©ì–´).
    """
    if teams_df is None or teams_df.empty:
        st.warning("ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒ íŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    required = {"íŒ€ëª…", "ìŠ¹", "p_wpct", "ì”ì—¬ê²½ê¸°"}
    missing = [c for c in required if c not in teams_df.columns]
    if missing:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing)}")
        return {}

    df = teams_df.copy()
    # íƒ€ì… ì •ë¦¬
    df["ì”ì—¬ê²½ê¸°"] = pd.to_numeric(df["ì”ì—¬ê²½ê¸°"], errors="coerce").fillna(0).astype(int).clip(lower=0)
    df["ìŠ¹"] = pd.to_numeric(df["ìŠ¹"], errors="coerce").fillna(0).astype(int)
    df["p_wpct"] = pd.to_numeric(df["p_wpct"], errors="coerce").fillna(0.0).astype(float)

    # íŒ€ëª… ì •ê·œí™”
    df = normalize_team_names(df)

    # ìœ íš¨ íŒ€ë§Œ(ìˆ˜ì¹˜í˜• NaN ì œê±°)
    df = df.loc[df["p_wpct"].notna() & df["ìŠ¹"].notna() & df["ì”ì—¬ê²½ê¸°"].notna()].reset_index(drop=True)
    T = len(df)
    if T == 0:
        st.warning("ìœ íš¨í•œ íŒ€ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return {}

    names = df["íŒ€ëª…"].tolist()
    current_wins = df["ìŠ¹"].to_numpy(dtype=int)
    p = df["p_wpct"].to_numpy(dtype=float)
    n_remain = df["ì”ì—¬ê²½ê¸°"].to_numpy(dtype=int)

    # ì”ì—¬ê²½ê¸° ì „ì²´ 0ì¸ ê²½ìš°: í˜„ì¬ ìŠ¹ìˆ˜ ê¸°ì¤€
    if np.all(n_remain == 0):
        winners = {n: 0.0 for n in names}
        winners[names[int(np.argmax(current_wins))]] = 100.0
        st.info("ëª¨ë“  íŒ€ì˜ ì”ì—¬ ê²½ê¸°ê°€ 0ì…ë‹ˆë‹¤. í˜„ì¬ ìŠ¹ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìš°ìŠ¹ í™•ë¥ ì„ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.")
        return winners

    wins_count = {n: 0 for n in names}
    prog = st.progress(0.0)
    text = st.empty()

    # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬/ì†ë„ ê· í˜•
    batch = 10_000
    n_batches = int(np.ceil(num_simulations / batch))

    for b in range(n_batches):
        this_batch = batch if (b + 1) * batch <= num_simulations else (num_simulations - b * batch)
        if this_batch <= 0:
            continue

        # (B, T) ë°°ì—´ì„ "ì—´(íŒ€)ë³„"ë¡œ ìƒì„± â†’ n,pê°€ ë²¡í„°ì—¬ë„ ì•ˆì „
        sim = np.empty((this_batch, T), dtype=int)
        for t in range(T):
            nt = int(n_remain[t]); pt = float(p[t])
            if nt <= 0 or pt <= 0.0:
                sim[:, t] = 0
            elif pt >= 1.0:
                sim[:, t] = nt
            else:
                sim[:, t] = np.random.binomial(n=nt, p=pt, size=this_batch)

        final_wins = sim + current_wins  # (B, T)
        if final_wins.size == 0:
            # ì•ˆì „ë§: T==0 ë˜ëŠ” B==0
            continue

        idx = np.argmax(final_wins, axis=1)  # (B,)
        for i in idx:
            wins_count[names[int(i)]] += 1

        if b % 2 == 0:
            prog.progress((b + 1) / n_batches)
            text.text(f"ìš°ìŠ¹ í™•ë¥  ê³„ì‚° ì¤‘... {min((b + 1) * batch, num_simulations):,}/{num_simulations:,}")

    prog.progress(1.0)
    text.text("ìš°ìŠ¹ í™•ë¥  ê³„ì‚° ì™„ë£Œ!")
    return {k: v / num_simulations * 100.0 for k, v in wins_count.items()}

def calculate_playoff_probability(teams_df: pd.DataFrame, num_simulations: int = 50_000) -> dict:
    """
    ìƒìœ„ 5íŒ€ í”Œë ˆì´ì˜¤í”„ ì§„ì¶œ í™•ë¥ (ë¹ˆ DF/íŒ€ ìˆ˜ < 5/ì”ì—¬ê²½ê¸° 0 ë°©ì–´).
    """
    if teams_df is None or teams_df.empty:
        st.warning("ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒ íŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    required = {"íŒ€ëª…", "ìŠ¹", "p_wpct", "ì”ì—¬ê²½ê¸°"}
    missing = [c for c in required if c not in teams_df.columns]
    if missing:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing)}")
        return {}

    df = teams_df.copy()
    df["ì”ì—¬ê²½ê¸°"] = pd.to_numeric(df["ì”ì—¬ê²½ê¸°"], errors="coerce").fillna(0).astype(int).clip(lower=0)
    df["ìŠ¹"] = pd.to_numeric(df["ìŠ¹"], errors="coerce").fillna(0).astype(int)
    df["p_wpct"] = pd.to_numeric(df["p_wpct"], errors="coerce").fillna(0.0).astype(float)

    df = normalize_team_names(df)
    df = df.loc[df["p_wpct"].notna() & df["ìŠ¹"].notna() & df["ì”ì—¬ê²½ê¸°"].notna()].reset_index(drop=True)

    T = len(df)
    if T == 0:
        st.warning("ìœ íš¨í•œ íŒ€ ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return {}

    names = df["íŒ€ëª…"].tolist()
    current_wins = df["ìŠ¹"].to_numpy(dtype=int)
    p = df["p_wpct"].to_numpy(dtype=float)
    n_remain = df["ì”ì—¬ê²½ê¸°"].to_numpy(dtype=int)

    top_k = min(5, T)
    po_counts = {n: 0 for n in names}
    prog = st.progress(0.0)
    text = st.empty()

    batch = 10_000
    n_batches = int(np.ceil(num_simulations / batch))

    for b in range(n_batches):
        this_batch = batch if (b + 1) * batch <= num_simulations else (num_simulations - b * batch)
        if this_batch <= 0:
            continue

        sim = np.empty((this_batch, T), dtype=int)
        for t in range(T):
            nt = int(n_remain[t]); pt = float(p[t])
            if nt <= 0 or pt <= 0.0:
                sim[:, t] = 0
            elif pt >= 1.0:
                sim[:, t] = nt
            else:
                sim[:, t] = np.random.binomial(n=nt, p=pt, size=this_batch)

        final_wins = sim + current_wins
        if final_wins.size == 0:
            continue

        # ë¹ ë¥¸ ìƒìœ„ ì„ íƒ
        topk_idx = np.argpartition(-final_wins, kth=top_k - 1, axis=1)[:, :top_k]
        rows = np.arange(final_wins.shape[0])[:, None]
        ordered = topk_idx[rows, np.argsort(-final_wins[rows, topk_idx], axis=1)]

        for row in ordered:
            for i in row:
                po_counts[names[int(i)]] += 1

        if b % 2 == 0:
            prog.progress((b + 1) / n_batches)
            text.text(f"í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì¤‘... {min((b + 1) * batch, num_simulations):,}/{num_simulations:,}")

    prog.progress(1.0)
    text.text("í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì™„ë£Œ!")
    return {k: v / num_simulations * 100.0 for k, v in po_counts.items()}

def _validate_sim_inputs(df_final: pd.DataFrame) -> bool:
    """ì‹œë®¬ ì‹œì‘ ì „ ì…ë ¥ ê²€ì¦. ë¬¸ì œê°€ ìˆìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì›ì¸ í‘œì‹œí•˜ê³  False."""
    need = {"íŒ€ëª…", "ìŠ¹", "p_wpct", "ì”ì—¬ê²½ê¸°"}
    if df_final is None or df_final.empty:
        st.error("ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤(df_final).")
        return False
    miss = [c for c in need if c not in df_final.columns]
    if miss:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(miss)}")
        return False
    if df_final["íŒ€ëª…"].isna().all():
        st.error("íŒ€ëª… ì»¬ëŸ¼ì´ ë¹„ì–´ ìˆì–´ ì‹œë®¬ë ˆì´ì…˜ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    return True

# -----------------------------
# ë©”ì¸
# -----------------------------
def main():
    st.markdown('<h1 class="main-header">âš¾ KBO íŒ€ í†µê³„ ë¶„ì„ê¸°</h1>', unsafe_allow_html=True)

    # ë°ì´í„° ë¡œë”©
    with st.spinner("ì‹¤ì‹œê°„ KBO ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        df_hitter = scrape_kbo_team_batting_stats()
        df_hitter_adv = scrape_kbo_team_batting_stats_advanced()
        df_pitcher = scrape_kbo_team_pitching_stats()
        df_pitcher_adv = scrape_kbo_team_pitching_stats_advanced()
        df_standings, date_info = scrape_kbo_standings()

    if any(x is None for x in [df_hitter, df_hitter_adv, df_pitcher, df_pitcher_adv, df_standings]):
        st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return

    # íŒ€ëª… ì •ê·œí™”(ë³‘í•© ì „)
    df_hitter = normalize_team_names(df_hitter)
    df_hitter_adv = normalize_team_names(df_hitter_adv)
    df_pitcher = normalize_team_names(df_pitcher)
    df_pitcher_adv = normalize_team_names(df_pitcher_adv)
    df_standings = normalize_team_names(df_standings)

    if date_info:
        st.markdown(
            f'<p style="text-align:center;font-size:1rem;color:#666;margin-top:-1rem;margin-bottom:2rem;">{date_info}</p>',
            unsafe_allow_html=True
        )

    # ê²°í•©
    df_hitter_combined = pd.merge(
        df_hitter,
        df_hitter_adv[['íŒ€ëª…','BB','IBB','HBP','SO','GDP','SLG','OBP','OPS','MH','RISP']],
        on='íŒ€ëª…', how='left'
    )
    df_pitcher_combined = pd.merge(
        df_pitcher,
        df_pitcher_adv[['íŒ€ëª…','CG','SHO','QS','BSV','TBF','NP','AVG','2B','3B','SAC','SF','IBB','WP','BK']],
        on='íŒ€ëª…', how='left'
    )

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ˆ í˜„ì¬ ìˆœìœ„", "ğŸŸï¸ íŒ€ë³„ ê¸°ë¡", "ğŸ“Š ì‹œê°í™”", "ğŸ† ìš°ìŠ¹ í™•ë¥ ", "ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥"])

    with tab1:
        # í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥  ê³„ì‚°
        df_runs = pd.merge(
            df_hitter[['íŒ€ëª…','R']],
            df_pitcher[['íŒ€ëª…','R']],
            on='íŒ€ëª…', how='left', suffixes=('', '_A')
        )
        df_runs.rename(columns={'R': 'R', 'R_A': 'RA'}, inplace=True)
        p_n = 1.834
        df_runs['p_wpct'] = (df_runs['R']**p_n) / ((df_runs['R']**p_n) + (df_runs['RA']**p_n))
        df_runs['p_wpct'] = df_runs['p_wpct'].round(4)

        df_final = pd.merge(df_standings, df_runs[['íŒ€ëª…','p_wpct']], on='íŒ€ëª…', how='left')
        df_final['ì”ì—¬ê²½ê¸°'] = (144 - df_final['ê²½ê¸°']).clip(lower=0)

        # ê¸°ë³¸ ê¸°ëŒ€ìŠ¹ìˆ˜
        np.random.seed(42)
        df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜'] = [
            monte_carlo_expected_wins(p=float(r['ìŠ¹ë¥ ']), n_games=int(r['ì”ì—¬ê²½ê¸°']), n_sims=10_000)
            for _, r in df_final.iterrows()
        ]
        df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜'] = [
            monte_carlo_expected_wins(p=float(r['p_wpct']), n_games=int(r['ì”ì—¬ê²½ê¸°']), n_sims=10_000)
            for _, r in df_final.iterrows()
        ]
        df_final['ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜'] = (df_final['ìŠ¹'] + df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_ìŠ¹ë¥ ê¸°ë°˜']).round(1)
        df_final['ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜'] = (df_final['ìŠ¹'] + df_final['ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜']).round(1)

        st.session_state['df_final'] = df_final.copy()

        st.subheader("ğŸ“Š í˜„ì¬ ìˆœìœ„ ë° ì˜ˆì¸¡ ë¶„ì„")
        display = df_final[['ìˆœìœ„','íŒ€ëª…','ê²½ê¸°','ìŠ¹','íŒ¨','ë¬´','ìŠ¹ë¥ ','ê²Œì„ì°¨','ìµœê·¼10ê²½ê¸°','p_wpct','ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜']].copy()
        display.rename(columns={'p_wpct':'í”¼íƒ€ê³ ë¦¬ì•ˆìŠ¹ë¥ ','ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜':'ì˜ˆìƒìµœì¢…ìŠ¹ìˆ˜'}, inplace=True)
        display['í”¼íƒ€ê³ ë¦¬ì•ˆìŠ¹ë¥ '] = display['í”¼íƒ€ê³ ë¦¬ì•ˆìŠ¹ë¥ '].round(4)
        safe_dataframe_display(clean_dataframe_for_display(display), use_container_width=True, hide_index=True)

    with tab2:
        st.header("ğŸŸï¸ íŒ€ë³„ ê¸°ë¡")
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("íƒ€ì ê¸°ë¡")
            safe_dataframe_display(clean_dataframe_for_display(df_hitter_combined), True, True)
        with c2:
            st.subheader("íˆ¬ìˆ˜ ê¸°ë¡")
            safe_dataframe_display(clean_dataframe_for_display(df_pitcher_combined), True, True)

        st.subheader("ğŸ† TOP 3 íŒ€")
        l, r = st.columns(2)
        with l:
            st.subheader("íƒ€ê²© ìƒìœ„ 3íŒ€")
            top3_avg = df_hitter_combined.nlargest(3, 'AVG')[['íŒ€ëª…','AVG']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in top3_avg.iterrows():
                cols[i].metric(f"{i+1}ìœ„ {row['íŒ€ëª…']}", f"{row['AVG']:.3f}")
            st.write("**OPS ìƒìœ„ 3íŒ€**")
            top3_ops = df_hitter_combined.nlargest(3, 'OPS')[['íŒ€ëª…','OPS']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in top3_ops.iterrows():
                cols[i].metric(f"{i+1}ìœ„ {row['íŒ€ëª…']}", f"{row['OPS']:.3f}")
        with r:
            st.subheader("íˆ¬ìˆ˜ ìƒìœ„ 3íŒ€")
            st.write("**ERA ìƒìœ„ 3íŒ€ (ë‚®ì€ ìˆœ)**")
            top3_era = df_pitcher_combined.nsmallest(3, 'ERA')[['íŒ€ëª…','ERA']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in enumerate(top3_era.itertuples(index=False)):
                cols[i].metric(f"{i+1}ìœ„ {row.íŒ€ëª…}", f"{row.ERA:.2f}")
            st.write("**WHIP ìƒìœ„ 3íŒ€ (ë‚®ì€ ìˆœ)**")
            top3_whip = df_pitcher_combined.nsmallest(3, 'WHIP')[['íŒ€ëª…','WHIP']].reset_index(drop=True)
            cols = st.columns(3)
            for i, row in enumerate(top3_whip.itertuples(index=False)):
                cols[i].metric(f"{i+1}ìœ„ {row.íŒ€ëª…}", f"{row.WHIP:.2f}")

    with tab3:
        st.header("ğŸ“Š ì‹œê°í™”")
        c1, c2 = st.columns(2)
        with c1:
            fig1 = px.scatter(df_hitter_combined, x='AVG', y='HR', title="íƒ€ìœ¨ vs í™ˆëŸ°", hover_data=['íŒ€ëª…'], text='íŒ€ëª…')
            fig1.update_traces(textposition="top center", marker_size=12)
            fig1.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig1.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            st.plotly_chart(fig1, use_container_width=True)
        with c2:
            fig2 = px.scatter(df_pitcher_combined, x='ERA', y='SO', title="ERA vs ì‚¼ì§„", hover_data=['íŒ€ëª…'], text='íŒ€ëª…')
            fig2.update_traces(textposition="top center", marker_size=12)
            fig2.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig2.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            st.plotly_chart(fig2, use_container_width=True)

        df_final = st.session_state['df_final']
        fig3 = px.scatter(df_final, x='ìŠ¹ë¥ ', y='p_wpct', title="ì‹¤ì œ ìŠ¹ë¥  vs í”¼íƒ€ê³ ë¦¬ì•ˆ ìŠ¹ë¥ ", hover_data=['íŒ€ëª…'], text='íŒ€ëª…')
        fig3.add_trace(go.Scatter(x=[0.25, 0.65], y=[0.25, 0.65], mode='lines', name='ê¸°ì¤€ì„ ',
                                  line=dict(dash='dash', color='red')))
        fig3.update_traces(textposition="top center", marker_size=12)
        fig3.update_xaxes(range=[0.25, 0.65], showgrid=True, gridwidth=1, gridcolor='lightgray')
        fig3.update_yaxes(range=[0.25, 0.65], showgrid=True, gridwidth=1, gridcolor='lightgray')
        st.plotly_chart(fig3, use_container_width=True)

    with tab4:
        df_final = st.session_state['df_final']
        c1, c2 = st.columns(2)
        with c1:
            championship_simulations = st.slider("ìš°ìŠ¹ í™•ë¥  ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", 5_000, 50_000, 5_000, step=5_000)
        with c2:
            playoff_simulations = st.slider("í”Œë ˆì´ì˜¤í”„ í™•ë¥  ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", 5_000, 50_000, 5_000, step=5_000)

        if 'df_final' in st.session_state:
            with st.expander("ğŸ”§ ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ ë””ë²„ê·¸", expanded=False):
                df_dbg = st.session_state['df_final'].copy()
                st.write("ì…ë ¥ DF ìƒ˜í”Œ:", df_dbg.head(10))
                st.write("í–‰/ì—´:", df_dbg.shape)
                st.write("í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€:", {c: (c in df_dbg.columns) for c in ["íŒ€ëª…","ìŠ¹","p_wpct","ì”ì—¬ê²½ê¸°"]})
                st.write("ê²°ì¸¡ì¹˜ ê°œìˆ˜:", df_dbg[["íŒ€ëª…","ìŠ¹","p_wpct","ì”ì—¬ê²½ê¸°"]].isna().sum())


        if st.button("ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
            with st.spinner("ìš°ìŠ¹/í”Œë ˆì´ì˜¤í”„ í™•ë¥  ê³„ì‚° ì¤‘..."):
                champs = calculate_championship_probability(df_final, championship_simulations)
                df_final['ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸'] = df_final['íŒ€ëª…'].map(champs)
                po = calculate_playoff_probability(df_final, playoff_simulations)
                df_final['í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸'] = df_final['íŒ€ëª…'].map(po)

                log_df = df_final[['íŒ€ëª…','ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸','í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸']].copy()
                append_simulation_to_sheet(log_df, "SimulationLog")

                display_col = 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜' if 'ìµœì¢…ê¸°ëŒ€ìŠ¹ìˆ˜_í”¼íƒ€ê³ ë¦¬ì•ˆê¸°ë°˜' in df_final.columns else 'ìŠ¹'
                combined = df_final[['ìˆœìœ„','íŒ€ëª…',display_col,'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸','í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸']].copy()
                combined.rename(columns={display_col:'ì˜ˆìƒìµœì¢…ìŠ¹ìˆ˜'}, inplace=True)
                combined = combined.sort_values('ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', ascending=False).reset_index(drop=True)

                st.subheader("ğŸ† KBO ìš°ìŠ¹ í™•ë¥  & PO ì§„ì¶œ í™•ë¥ ")
                cc1, cc2 = st.columns(2)
                with cc1:
                    disp = clean_dataframe_for_display(combined).rename(
                        columns={'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸':'ìš°ìŠ¹í™•ë¥ ','í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸':'POí™•ë¥ '}
                    )
                    safe_dataframe_display(disp, True, True)
                with cc2:
                    fig = px.bar(combined, x='íŒ€ëª…', y='ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', title="íŒ€ë³„ ìš°ìŠ¹ í™•ë¥ ",
                                 color='ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸', color_continuous_scale='RdYlGn')
                    fig.update_layout(xaxis_tickangle=-45)
                    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                    st.plotly_chart(fig, use_container_width=True)

                fig2 = px.bar(combined, x='íŒ€ëª…', y='í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸', title="íŒ€ë³„ í”Œë ˆì´ì˜¤í”„ ì§„ì¶œ í™•ë¥ ",
                              color='í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸', color_continuous_scale='Blues')
                fig2.update_layout(xaxis_tickangle=-45)
                fig2.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                fig2.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
                st.plotly_chart(fig2, use_container_width=True)

    with tab5:
        st.header("ğŸ“… ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥")
        try:
            client = get_gsheet_client()
            if client is None:
                st.info("Google Sheets ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.warning("ì§„ë‹¨ ì •ë³´:\n" + _diagnose_gsheet_setup())
            else:
                try:
                    ws = client.open("KBO_Simulation_Log").worksheet("SimulationLog")
                except Exception:
                    st.info("ì•„ì§ ë¡œê·¸ ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìš°ìŠ¹ í™•ë¥  íƒ­ì—ì„œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
                    return
                history = ws.get_all_records()
                df_hist = pd.DataFrame(history)
                if df_hist.empty:
                    st.info("ì•„ì§ ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    df_hist['timestamp'] = pd.to_datetime(df_hist['timestamp'])
                    df_sum = df_hist.groupby('timestamp', as_index=False).agg({
                        'ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸':'mean',
                        'í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸':'mean'
                    })
                    fig = px.line(df_sum, x='timestamp',
                                  y=['ìš°ìŠ¹í™•ë¥ _í¼ì„¼íŠ¸','í”Œë ˆì´ì˜¤í”„ì§„ì¶œí™•ë¥ _í¼ì„¼íŠ¸'],
                                  title='ì¼ìë³„ í‰ê·  ìš°ìŠ¹ / í”Œë ˆì´ì˜¤í”„ í™•ë¥ ', markers=True)
                    fig.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title="í™•ë¥ (%)")
                    st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.info(f"Google Sheets ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {e}")

if __name__ == "__main__":
    main()
